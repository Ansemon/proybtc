
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>&lt;no title&gt; &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'miniproyecto2nuevo';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to your Jupyter Book" href="intro.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        
    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fminiproyecto2nuevo.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/miniproyecto2nuevo.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1><no title></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="simple visible nav section-nav flex-column">
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Cargar dataset</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;btc_1d_data_2018_to_2025.csv&quot;</span><span class="p">)</span>

<span class="c1"># Selección de columnas</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Open time&#39;</span><span class="p">,</span> <span class="s1">&#39;Close&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Open time&#39;</span><span class="p">:</span> <span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="s1">&#39;Close&#39;</span><span class="p">:</span> <span class="s1">&#39;Close&#39;</span><span class="p">})</span>

<span class="c1"># Conversión de tipos</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">])</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_numeric</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">],</span> <span class="n">errors</span><span class="o">=</span><span class="s1">&#39;coerce&#39;</span><span class="p">)</span>

<span class="c1"># Limpieza</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;Date&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape final:&quot;</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Rango fechas:&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="s2">&quot;→&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Duración en días:&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">())</span><span class="o">.</span><span class="n">days</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">ModuleNotFoundError</span><span class="g g-Whitespace">                       </span>Traceback (most recent call last)
<span class="n">Cell</span> <span class="n">In</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">line</span> <span class="mi">3</span>
<span class="g g-Whitespace">      </span><span class="mi">1</span> <span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="ne">----&gt; </span><span class="mi">3</span> <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="c1"># Cargar dataset</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;btc_1d_data_2018_to_2025.csv&quot;</span><span class="p">)</span>

<span class="n">File</span> <span class="o">~</span>\<span class="n">miniconda3</span>\<span class="n">Lib</span>\<span class="n">site</span><span class="o">-</span><span class="n">packages</span>\<span class="n">matplotlib</span>\<span class="fm">__init__</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">161</span>
<span class="g g-Whitespace">    </span><span class="mi">157</span> <span class="kn">from</span><span class="w"> </span><span class="nn">packaging.version</span><span class="w"> </span><span class="kn">import</span> <span class="n">parse</span> <span class="k">as</span> <span class="n">parse_version</span>
<span class="g g-Whitespace">    </span><span class="mi">159</span> <span class="c1"># cbook must import matplotlib only within function</span>
<span class="g g-Whitespace">    </span><span class="mi">160</span> <span class="c1"># definitions, so it is safe to import from it here.</span>
<span class="ne">--&gt; </span><span class="mi">161</span> <span class="kn">from</span><span class="w"> </span><span class="nn">.</span><span class="w"> </span><span class="kn">import</span> <span class="n">_api</span><span class="p">,</span> <span class="n">_version</span><span class="p">,</span> <span class="n">cbook</span><span class="p">,</span> <span class="n">_docstring</span><span class="p">,</span> <span class="n">rcsetup</span>
<span class="g g-Whitespace">    </span><span class="mi">162</span> <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib._api</span><span class="w"> </span><span class="kn">import</span> <span class="n">MatplotlibDeprecationWarning</span>
<span class="g g-Whitespace">    </span><span class="mi">163</span> <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.rcsetup</span><span class="w"> </span><span class="kn">import</span> <span class="n">cycler</span>  <span class="c1"># noqa: F401</span>

<span class="n">File</span> <span class="o">~</span>\<span class="n">miniconda3</span>\<span class="n">Lib</span>\<span class="n">site</span><span class="o">-</span><span class="n">packages</span>\<span class="n">matplotlib</span>\<span class="n">rcsetup</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">26</span>
<span class="g g-Whitespace">     </span><span class="mi">23</span> <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="g g-Whitespace">     </span><span class="mi">25</span> <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">_api</span><span class="p">,</span> <span class="n">cbook</span>
<span class="ne">---&gt; </span><span class="mi">26</span> <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.backends</span><span class="w"> </span><span class="kn">import</span> <span class="n">BackendFilter</span><span class="p">,</span> <span class="n">backend_registry</span>
<span class="g g-Whitespace">     </span><span class="mi">27</span> <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.cbook</span><span class="w"> </span><span class="kn">import</span> <span class="n">ls_mapper</span>
<span class="g g-Whitespace">     </span><span class="mi">28</span> <span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.colors</span><span class="w"> </span><span class="kn">import</span> <span class="n">Colormap</span><span class="p">,</span> <span class="n">is_color_like</span>

<span class="n">File</span> <span class="o">~</span>\<span class="n">miniconda3</span>\<span class="n">Lib</span>\<span class="n">site</span><span class="o">-</span><span class="n">packages</span>\<span class="n">matplotlib</span>\<span class="n">backends</span>\<span class="fm">__init__</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">1</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="kn">from</span><span class="w"> </span><span class="nn">.registry</span><span class="w"> </span><span class="kn">import</span> <span class="n">BackendFilter</span><span class="p">,</span> <span class="n">backend_registry</span>  <span class="c1"># noqa: F401</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> <span class="c1"># NOTE: plt.switch_backend() (called at import time) will add a &quot;backend&quot;</span>
<span class="g g-Whitespace">      </span><span class="mi">4</span> <span class="c1"># attribute here for backcompat.</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">_QT_FORCE_QT5_BINDING</span> <span class="o">=</span> <span class="kc">False</span>

<span class="ne">ModuleNotFoundError</span>: No module named &#39;matplotlib.backends.registry&#39;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Precio BTC&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;steelblue&#39;</span><span class="p">)</span>

<span class="c1"># Eventos destacados</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s2">&quot;2020-03-15&quot;</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;COVID-19&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s2">&quot;2021-01-01&quot;</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Bull Run 2021&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;📈 Serie Temporal de Precios BTC (USD)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Fecha&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Precio (USD)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="c1"># Eliminar el primer NaN generado por el shift</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;log_return&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/6a52356097eed5a424d8014951338f675bbbcac396fe43ea6e80b10d06a2b59e.png" src="_images/6a52356097eed5a424d8014951338f675bbbcac396fe43ea6e80b10d06a2b59e.png" />
</div>
</div>
<p>El gráfico de la serie temporal del precio de Bitcoin muestra un crecimiento significativo con ciclos de expansión y contracción. Se observan caídas abruptas durante el inicio de la pandemia de COVID-19 (marzo 2020), así como un incremento acelerado en el bull run de 2021. Posteriormente, el precio atraviesa una fuerte corrección en 2022, para luego recuperar tendencia alcista hacia 2024–2025. Esto confirma que Bitcoin es altamente sensible a eventos externos y presenta una dinámica especulativa marcada por fases de volatilidad extrema</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

<span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;coral&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;📉 Retornos Logarítmicos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Fecha&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Retorno&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;density&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>

<span class="c1"># Curva normal ajustada</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Normal(μ=</span><span class="si">{</span><span class="n">mu</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">, σ=</span><span class="si">{</span><span class="n">sigma</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Media: </span><span class="si">{</span><span class="n">mu</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;📊 Distribución de Retornos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Retorno&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Densidad&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/473299bfef8cb23b1b398d7ed1d520b19ea237c0aca412b241a7848d452b4d18.png" src="_images/473299bfef8cb23b1b398d7ed1d520b19ea237c0aca412b241a7848d452b4d18.png" />
<img alt="_images/b34c0496526d86f51109f0def14eae6a6c8572c0bd36e4345c24f99e00053887.png" src="_images/b34c0496526d86f51109f0def14eae6a6c8572c0bd36e4345c24f99e00053887.png" />
</div>
</div>
<p>en el grafico de retornos
observamos que los retornos logarítmicos se concentran en torno a cero, pero presentan valores extremos en momentos de crisis (ej. COVID-19 en 2020) y durante fases de fuerte expansión (bull run 2021). Esto evidencia que, aunque el promedio de retornos diarios es bajo, la dispersión es elevada, lo que refuerza la idea de que Bitcoin es un activo riesgoso con alta exposición a eventos de cola.</p>
<p>por otro lado la distribución de los retornos de Bitcoin presenta una media cercana a cero (μ ≈ 0.0008), con una dispersión relativamente alta (σ ≈ 0.0357). La comparación con la curva normal ajustada muestra que los retornos exhiben colas pesadas y mayor concentración alrededor de la media, lo cual indica un comportamiento no gaussiano. Esto implica que los modelos que asumen normalidad subestiman la probabilidad de eventos extremos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>

<span class="n">sm</span><span class="o">.</span><span class="n">qqplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dropna</span><span class="p">(),</span> <span class="n">line</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;📐 Q-Q Plot vs Normal&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/d3c7f0bf6d64c47e07a15a65ce4f2ed07ff7c647d0b86eb58c26fc5a81627380.png" src="_images/d3c7f0bf6d64c47e07a15a65ce4f2ed07ff7c647d0b86eb58c26fc5a81627380.png" />
</div>
</div>
<p>como ya habiamos dicho, el Q-Q plot muestra desviaciones claras en las colas respecto a la distribución normal: los puntos se alejan de la línea de referencia tanto en valores extremos negativos como positivos. Esto confirma que los retornos de Bitcoin no son normales y presentan riesgo de eventos extremos, en especial negativos. En otras palabras, el mercado de BTC es más volátil y arriesgado de lo que asumiría un modelo gaussiano.”</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">window</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Vol_7d&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;LogRet&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">365</span><span class="p">)</span>  <span class="c1"># anualizada</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Vol_7d&#39;</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;purple&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;📉 Volatilidad Histórica (7d)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Fecha&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Volatilidad Anualizada&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4880e1c2b25359a92ee7e55939139e697131d2888f5c98430983c9492770b248.png" src="_images/4880e1c2b25359a92ee7e55939139e697131d2888f5c98430983c9492770b248.png" />
</div>
</div>
<p>La volatilidad histórica calculada con una ventana de 7 días muestra episodios de clustering de volatilidad: periodos de calma seguidos de picos muy altos. En particular, se observan valores extremos durante la pandemia de COVID-19 y el bull run de 2021. Esto confirma que la volatilidad de Bitcoin no es constante en el tiempo, sino que presenta heterocedasticidad lo cual nos da sugerencias sobre que tipo de modelos podrian ser mas efectivos en este problema especifico</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Asegurar columna fecha</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">])</span>

<span class="c1"># Retornos logarítmicos</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;log_return&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">diff</span><span class="p">()</span>

<span class="c1"># Día de la semana (0=lunes, 6=domingo)</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;weekday&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">day_name</span><span class="p">()</span>

<span class="c1"># Volatilidad por día de la semana</span>
<span class="n">vol_by_weekday</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;weekday&#39;</span><span class="p">)[</span><span class="s1">&#39;log_return&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="o">.</span><span class="n">sort_index</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">vol_by_weekday</span><span class="p">)</span>

<span class="c1"># Visualización</span>
<span class="n">vol_by_weekday</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Volatilidad por día de la semana&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Desviación estándar de los retornos&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>weekday
Friday       0.035117
Monday       0.041776
Saturday     0.023354
Sunday       0.028639
Thursday     0.045376
Tuesday      0.036060
Wednesday    0.037713
Name: log_return, dtype: float64
</pre></div>
</div>
<img alt="_images/a82f381a0ad656d675a400471b99c4bdb299d090b945101e9f25b073a4a849b3.png" src="_images/a82f381a0ad656d675a400471b99c4bdb299d090b945101e9f25b073a4a849b3.png" />
</div>
</div>
<p>El EDA revela fuerte estacionalidad semanal y posible heterocedasticidad, esto nos indica promesa sobre los lagas mas grandes capaces de atrapar estas variaciones</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Estadísticas descriptivas del precio de cierre</span>
<span class="n">desc_stats</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>

<span class="c1"># Histograma y KDE del precio de cierre</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribución del Precio de Cierre del Bitcoin&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Precio de cierre (USD)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Frecuencia&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">desc_stats</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3c54d81eab6d4927c194ef813f3a76b791a3648e979f8ad904f3a06868ab7045.png" src="_images/3c54d81eab6d4927c194ef813f3a76b791a3648e979f8ad904f3a06868ab7045.png" />
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>count      2594.000000
mean      29090.193446
std       23576.229505
min        3211.720000
25%        9068.840000
50%       22741.115000
75%       43527.390000
max      106143.820000
Name: Close, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>La estadística descriptiva confirma la alta dispersión y asimetría de los precios del Bitcoin, un rasgo que justifica el análisis posterior de la volatilidad como variable fundamental en modelos predictivos.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#funcional mlp perfecto</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neural_network</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tsxv.splitTrainValTest</span><span class="w"> </span><span class="kn">import</span> <span class="n">split_train_val_test_groupKFold</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Utilidades</span>
<span class="c1"># ---------------------------</span>
<span class="k">def</span><span class="w"> </span><span class="nf">mape</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)))</span> <span class="o">*</span> <span class="mf">100.0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">bds_test</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">max_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">eps_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">eps_factor</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">embed</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">m</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">correlation_integral</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">count</span> <span class="o">/</span> <span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">Xm</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
        <span class="n">X1</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">Cm</span> <span class="o">=</span> <span class="n">correlation_integral</span><span class="p">(</span><span class="n">Xm</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">C1</span> <span class="o">=</span> <span class="n">correlation_integral</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">bds_stat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">Cm</span> <span class="o">-</span> <span class="n">C1</span><span class="o">**</span><span class="n">m</span><span class="p">)</span>

        <span class="n">boot_stats</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_bootstrap</span><span class="p">):</span>
            <span class="n">shuffled</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>
            <span class="n">Xm_boot</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">shuffled</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
            <span class="n">Cmb</span> <span class="o">=</span> <span class="n">correlation_integral</span><span class="p">(</span><span class="n">Xm_boot</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
            <span class="n">C1b</span> <span class="o">=</span> <span class="n">correlation_integral</span><span class="p">(</span><span class="n">embed</span><span class="p">(</span><span class="n">shuffled</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">eps</span><span class="p">)</span>
            <span class="n">boot_stats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">Cmb</span> <span class="o">-</span> <span class="n">C1b</span><span class="o">**</span><span class="n">m</span><span class="p">))</span>
        <span class="n">boot_stats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">boot_stats</span><span class="p">)</span>
        <span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">boot_stats</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">bds_stat</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_bootstrap</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">bds_stat</span><span class="p">,</span> <span class="n">p_value</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">,</span> <span class="s1">&#39;statistic&#39;</span><span class="p">,</span> <span class="s1">&#39;p_value&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s2">&quot;m&quot;</span><span class="p">)</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Carga de datos</span>
<span class="c1"># ---------------------------</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;btc_1d_data_2018_to_2025.csv&quot;</span><span class="p">)</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[[</span><span class="s2">&quot;Open time&quot;</span><span class="p">,</span> <span class="s2">&quot;Close&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">btc</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Open time&quot;</span><span class="p">:</span> <span class="s2">&quot;Date&quot;</span><span class="p">})</span>
<span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">btc</span><span class="p">[</span><span class="s2">&quot;LogReturn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="n">window_size</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Volatility&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[</span><span class="s2">&quot;LogReturn&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">365</span><span class="p">)</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">btc</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">volatility_full</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Volatility&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Configuración de experimento</span>
<span class="c1"># ---------------------------</span>
<span class="n">n_steps_in_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">28</span><span class="p">]</span>
<span class="n">n_steps_out</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">n_steps_jump</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># Máxima densidad de datos</span>


<span class="n">mlp_hyperparams</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Arquitecturas enfocadas en las que funcionaron bien</span>
<span class="n">hidden_layers</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="mi">10</span><span class="p">,),</span> <span class="p">(</span><span class="mi">20</span><span class="p">,),</span> <span class="p">(</span><span class="mi">30</span><span class="p">,),</span> <span class="p">(</span><span class="mi">50</span><span class="p">,),</span> <span class="p">(</span><span class="mi">100</span><span class="p">,),</span> <span class="p">(</span><span class="mi">200</span><span class="p">,),</span>  <span class="c1"># Capas simples</span>
    <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">15</span><span class="p">),</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>  <span class="c1"># Dos capas</span>
<span class="p">]</span>

<span class="c1"># Activaciones que mostraron buenos resultados</span>
<span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="s2">&quot;tanh&quot;</span><span class="p">]</span>

<span class="c1"># Rango amplio de alpha incluyendo los exitosos</span>
<span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">]</span>

<span class="c1"># Learning rates enfocados en los exitosos</span>
<span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">5e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">5e-3</span><span class="p">]</span>

<span class="c1"># Max_iter variado</span>
<span class="n">max_iters</span> <span class="o">=</span> <span class="p">[</span><span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]</span>

<span class="c1"># Solo StandardScaler (funcionó bien antes)</span>
<span class="n">scaler_type</span> <span class="o">=</span> <span class="s2">&quot;standard&quot;</span>

<span class="k">for</span> <span class="n">hidden</span> <span class="ow">in</span> <span class="n">hidden_layers</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">activation</span> <span class="ow">in</span> <span class="n">activations</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">max_iter</span> <span class="ow">in</span> <span class="n">max_iters</span><span class="p">:</span>
                    <span class="n">mlp_hyperparams</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">:</span> <span class="n">hidden</span><span class="p">,</span>
                        <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="n">activation</span><span class="p">,</span>
                        <span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="n">alpha</span><span class="p">,</span>
                        <span class="s2">&quot;learning_rate_init&quot;</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span>
                        <span class="s2">&quot;max_iter&quot;</span><span class="p">:</span> <span class="n">max_iter</span><span class="p">,</span>
                        <span class="s2">&quot;scaler&quot;</span><span class="p">:</span> <span class="n">scaler_type</span>
                    <span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;CONFIGURACIÓN ENFOCADA EN HIPERPARÁMETROS EXITOSOS:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Total hyperparam combos: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mlp_hyperparams</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Cálculo: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">)</span><span class="si">}</span><span class="s2">×</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">)</span><span class="si">}</span><span class="s2">×</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span><span class="si">}</span><span class="s2">×</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span><span class="si">}</span><span class="s2">×</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">max_iters</span><span class="p">)</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">activations</span><span class="p">)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">learning_rates</span><span class="p">)</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">max_iters</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Architecturas: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">)</span><span class="si">}</span><span class="s2"> opciones (incluyendo las exitosas: 50, 200)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Activaciones: </span><span class="si">{</span><span class="n">activations</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Alphas: </span><span class="si">{</span><span class="n">alphas</span><span class="si">}</span><span class="s2"> (incluyendo 1e-5, 1e-4, 1e-3 que funcionaron)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Learning rates: </span><span class="si">{</span><span class="n">learning_rates</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Max_iter: </span><span class="si">{</span><span class="n">max_iters</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Scaler: Solo StandardScaler&quot;</span><span class="p">)</span>

<span class="n">summary_rows</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Loop principal</span>
<span class="c1"># ---------------------------</span>
<span class="k">for</span> <span class="n">n_steps_in</span> <span class="ow">in</span> <span class="n">n_steps_in_list</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== LAG </span><span class="si">{</span><span class="n">n_steps_in</span><span class="si">}</span><span class="s2"> ===&quot;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Xcv</span><span class="p">,</span> <span class="n">ycv</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">split_train_val_test_groupKFold</span><span class="p">(</span>
        <span class="n">volatility_full</span><span class="p">,</span>
        <span class="n">n_steps_in</span><span class="p">,</span>
        <span class="n">n_steps_out</span><span class="p">,</span>
        <span class="n">n_steps_jump</span>
    <span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Datos con n_steps_jump=</span><span class="si">{</span><span class="n">n_steps_jump</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Número de folds: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># Verificar si X contiene arrays o enteros</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s1">&#39;__len__&#39;</span><span class="p">):</span>  <span class="c1"># Es un array</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Tamaño promedio train: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">X</span><span class="p">])</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> muestras&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Tamaño promedio val: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">Xcv</span><span class="p">])</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> muestras&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Tamaño promedio test: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">Xtest</span><span class="p">])</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> muestras&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>  <span class="c1"># Es un entero o escalar</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Tamaños train: </span><span class="si">{</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;shape&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">X</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Tamaños val: </span><span class="si">{</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;shape&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">Xcv</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Tamaños test: </span><span class="si">{</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;shape&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">Xtest</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Error al calcular tamaños: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Tipo de X[0]: </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Forma de X[0]: </span><span class="si">{</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="nb">hasattr</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="s1">&#39;shape&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;No shape&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">folds_stats</span><span class="p">,</span> <span class="n">folds_bds</span><span class="p">,</span> <span class="n">folds_best_cfg</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">  Procesando Fold </span><span class="si">{</span><span class="n">fold</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="n">Xtr</span><span class="p">,</span> <span class="n">ytr</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">fold</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span>
        <span class="n">Xval</span><span class="p">,</span> <span class="n">yval</span> <span class="o">=</span> <span class="n">Xcv</span><span class="p">[</span><span class="n">fold</span><span class="p">],</span> <span class="n">ycv</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span>
        <span class="n">Xte</span><span class="p">,</span> <span class="n">yte</span> <span class="o">=</span> <span class="n">Xtest</span><span class="p">[</span><span class="n">fold</span><span class="p">],</span> <span class="n">ytest</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span>

        <span class="n">best_cfg</span><span class="p">,</span> <span class="n">best_rmse</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">best_scaler_x</span><span class="p">,</span> <span class="n">best_scaler_y</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

        <span class="c1"># Búsqueda exhaustiva en validación con progreso</span>
        <span class="k">for</span> <span class="n">cfg_idx</span><span class="p">,</span> <span class="n">cfg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mlp_hyperparams</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">cfg_idx</span> <span class="o">%</span> <span class="mi">50</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>  <span class="c1"># Progreso cada 50 configs</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Evaluando config </span><span class="si">{</span><span class="n">cfg_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mlp_hyperparams</span><span class="p">)</span><span class="si">}</span><span class="s2">... (</span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">cfg_idx</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">mlp_hyperparams</span><span class="p">)</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>
            
            <span class="c1"># Solo StandardScaler (simplificado)</span>
            <span class="n">scaler_x</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
            <span class="n">scaler_y</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

            <span class="n">Xtr_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Xtr</span><span class="p">)</span>
            <span class="n">ytr_s</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">ytr</span><span class="p">)</span>
            <span class="n">Xval_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xval</span><span class="p">)</span>

            <span class="n">model</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span>
                <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">],</span>
                <span class="n">activation</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
                <span class="n">alpha</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">],</span>
                <span class="n">learning_rate_init</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;learning_rate_init&quot;</span><span class="p">],</span>
                <span class="n">max_iter</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;max_iter&quot;</span><span class="p">],</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
                <span class="n">n_iter_no_change</span><span class="o">=</span><span class="mi">15</span>  <span class="c1"># Reducido de 20 para acelerar</span>
            <span class="p">)</span>

            <span class="k">try</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtr_s</span><span class="p">,</span> <span class="n">ytr_s</span><span class="p">)</span>
                <span class="n">yval_hat</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xval_s</span><span class="p">))</span>
                <span class="n">rmse_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yval</span><span class="p">[:,</span> <span class="n">h</span><span class="p">],</span> <span class="n">yval_hat</span><span class="p">[:,</span> <span class="n">h</span><span class="p">]))</span>
                    <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps_out</span><span class="p">)</span>
                <span class="p">])</span>

                <span class="k">if</span> <span class="n">rmse_val</span> <span class="o">&lt;</span> <span class="n">best_rmse</span><span class="p">:</span>
                    <span class="n">best_rmse</span><span class="p">,</span> <span class="n">best_cfg</span><span class="p">,</span> <span class="n">best_model</span> <span class="o">=</span> <span class="n">rmse_val</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">model</span>
                    <span class="n">best_scaler_x</span><span class="p">,</span> <span class="n">best_scaler_y</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="p">,</span> <span class="n">scaler_y</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="c1"># Si falla el entrenamiento, continuar con siguiente config</span>
                <span class="k">continue</span>

        <span class="n">folds_best_cfg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_cfg</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Mejor RMSE validación: </span><span class="si">{</span><span class="n">best_rmse</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Mejor config: </span><span class="si">{</span><span class="n">best_cfg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># RETRAIN: train+val</span>
        <span class="n">Xtrain_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Xval</span><span class="p">])</span>
        <span class="n">ytrain_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">ytr</span><span class="p">,</span> <span class="n">yval</span><span class="p">])</span>
        
        <span class="n">final_scaler_x</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        <span class="n">final_scaler_y</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        
        <span class="n">Xtrain_full_s</span> <span class="o">=</span> <span class="n">final_scaler_x</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Xtrain_full</span><span class="p">)</span>
        <span class="n">ytrain_full_s</span> <span class="o">=</span> <span class="n">final_scaler_y</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">ytrain_full</span><span class="p">)</span>

        <span class="n">final_model</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span>
            <span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">],</span>
            <span class="n">activation</span><span class="o">=</span><span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
            <span class="n">alpha</span><span class="o">=</span><span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">],</span>
            <span class="n">learning_rate_init</span><span class="o">=</span><span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;learning_rate_init&quot;</span><span class="p">],</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;max_iter&quot;</span><span class="p">],</span>
            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
            <span class="n">early_stopping</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">validation_fraction</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
            <span class="n">n_iter_no_change</span><span class="o">=</span><span class="mi">15</span>
        <span class="p">)</span>
        <span class="n">final_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_full_s</span><span class="p">,</span> <span class="n">ytrain_full_s</span><span class="p">)</span>

        <span class="c1"># Predicciones en test</span>
        <span class="n">Xte_s</span> <span class="o">=</span> <span class="n">final_scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xte</span><span class="p">)</span>
        <span class="n">yte_hat</span> <span class="o">=</span> <span class="n">final_scaler_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">final_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte_s</span><span class="p">))</span>
        <span class="n">yte_real</span> <span class="o">=</span> <span class="n">yte</span>

        <span class="c1"># Métricas por horizonte</span>
        <span class="n">metrics_per_h</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps_out</span><span class="p">):</span>
            <span class="n">mae_h</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yte_real</span><span class="p">[:,</span> <span class="n">h</span><span class="p">],</span> <span class="n">yte_hat</span><span class="p">[:,</span> <span class="n">h</span><span class="p">])</span>
            <span class="n">mse_h</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yte_real</span><span class="p">[:,</span> <span class="n">h</span><span class="p">],</span> <span class="n">yte_hat</span><span class="p">[:,</span> <span class="n">h</span><span class="p">])</span>
            <span class="n">rmse_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_h</span><span class="p">)</span>
            <span class="n">mape_h</span> <span class="o">=</span> <span class="n">mape</span><span class="p">(</span><span class="n">yte_real</span><span class="p">[:,</span> <span class="n">h</span><span class="p">],</span> <span class="n">yte_hat</span><span class="p">[:,</span> <span class="n">h</span><span class="p">])</span>
            <span class="n">metrics_per_h</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">mae_h</span><span class="p">,</span> <span class="n">mse_h</span><span class="p">,</span> <span class="n">rmse_h</span><span class="p">,</span> <span class="n">mape_h</span><span class="p">))</span>

        <span class="n">mae_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">m</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics_per_h</span><span class="p">])</span>
        <span class="n">mse_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics_per_h</span><span class="p">])</span>
        <span class="n">rmse_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">m</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics_per_h</span><span class="p">])</span>
        <span class="n">mape_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">m</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics_per_h</span><span class="p">])</span>

        <span class="c1"># BDS test en residuos horizonte 1</span>
        <span class="n">resid_h1</span> <span class="o">=</span> <span class="n">yte_real</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">yte_hat</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">bds_df</span> <span class="o">=</span> <span class="n">bds_test</span><span class="p">(</span><span class="n">resid_h1</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
        <span class="n">bds_pval_h1</span> <span class="o">=</span> <span class="n">bds_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;p_value&quot;</span><span class="p">]</span>

        <span class="n">folds_stats</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;fold&quot;</span><span class="p">:</span> <span class="n">fold</span><span class="p">,</span>
            <span class="s2">&quot;rmse_mean&quot;</span><span class="p">:</span> <span class="n">rmse_mean</span><span class="p">,</span>
            <span class="s2">&quot;mae_mean&quot;</span><span class="p">:</span> <span class="n">mae_mean</span><span class="p">,</span>
            <span class="s2">&quot;mse_mean&quot;</span><span class="p">:</span> <span class="n">mse_mean</span><span class="p">,</span>
            <span class="s2">&quot;mape_mean&quot;</span><span class="p">:</span> <span class="n">mape_mean</span><span class="p">,</span>
            <span class="s2">&quot;per_h_metrics&quot;</span><span class="p">:</span> <span class="n">metrics_per_h</span>
        <span class="p">})</span>
        <span class="n">folds_bds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bds_pval_h1</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Test final: MAE=</span><span class="si">{</span><span class="n">mae_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, RMSE=</span><span class="si">{</span><span class="n">rmse_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, MAPE=</span><span class="si">{</span><span class="n">mape_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%, BDS=</span><span class="si">{</span><span class="n">bds_pval_h1</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1"># Resumen por lag</span>
    <span class="n">rmse_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="s2">&quot;rmse_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">mae_arr</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="s2">&quot;mae_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">mse_arr</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="s2">&quot;mse_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">mape_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">s</span><span class="p">[</span><span class="s2">&quot;mape_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">bds_arr</span>  <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">folds_bds</span><span class="p">)</span>

    <span class="n">best_cfg_mode</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span> <span class="k">for</span> <span class="n">cfg</span> <span class="ow">in</span> <span class="n">folds_best_cfg</span><span class="p">])</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- RESUMEN LAG </span><span class="si">{</span><span class="n">n_steps_in</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; Mejor config (moda): </span><span class="si">{</span><span class="n">best_cfg_mode</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; MAE:  </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mae_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mae_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; MSE:  </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mse_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mse_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; RMSE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmse_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rmse_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; MAPE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mape_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mape_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; BDS:  </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bds_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> ± </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">bds_arr</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">summary_rows</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s2">&quot;Lag&quot;</span><span class="p">:</span> <span class="n">n_steps_in</span><span class="p">,</span>
        <span class="s2">&quot;Best_cfg_mode&quot;</span><span class="p">:</span> <span class="n">best_cfg_mode</span><span class="p">,</span>
        <span class="s2">&quot;MAE_mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mae_arr</span><span class="p">),</span> <span class="s2">&quot;MAE_std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mae_arr</span><span class="p">),</span>
        <span class="s2">&quot;MSE_mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mse_arr</span><span class="p">),</span> <span class="s2">&quot;MSE_std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mse_arr</span><span class="p">),</span>
        <span class="s2">&quot;RMSE_mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmse_arr</span><span class="p">),</span> <span class="s2">&quot;RMSE_std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rmse_arr</span><span class="p">),</span>
        <span class="s2">&quot;MAPE_mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mape_arr</span><span class="p">),</span> <span class="s2">&quot;MAPE_std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mape_arr</span><span class="p">),</span>
        <span class="s2">&quot;BDS_mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">bds_arr</span><span class="p">),</span> <span class="s2">&quot;BDS_std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">bds_arr</span><span class="p">)</span>
    <span class="p">})</span>

<span class="c1"># Resumen final comparativo</span>
<span class="n">df_final</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">summary_rows</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RESUMEN FINAL COMPARATIVO (n_steps_jump=1)&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_final</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">COMPUTACIÓN COMPLETADA:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Configuraciones evaluadas: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mlp_hyperparams</span><span class="p">)</span><span class="si">}</span><span class="s2"> por fold&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Total evaluaciones aproximadas: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mlp_hyperparams</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">n_steps_in_list</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="s1">&#39;avg_folds&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Reducción vs original: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">mlp_hyperparams</span><span class="p">)</span><span class="o">/</span><span class="mi">1344</span><span class="p">)</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">% menos configuraciones&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  - Uso de datos: Máximo (n_steps_jump=1)&quot;</span><span class="p">)</span>

<span class="c1"># Identificar mejor lag</span>
<span class="n">best_lag_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">([</span><span class="n">row</span><span class="p">[</span><span class="s2">&quot;RMSE_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">summary_rows</span><span class="p">])</span>
<span class="n">best_lag</span> <span class="o">=</span> <span class="n">summary_rows</span><span class="p">[</span><span class="n">best_lag_idx</span><span class="p">][</span><span class="s2">&quot;Lag&quot;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">MEJOR LAG: </span><span class="si">{</span><span class="n">best_lag</span><span class="si">}</span><span class="s2"> (RMSE promedio: </span><span class="si">{</span><span class="n">summary_rows</span><span class="p">[</span><span class="n">best_lag_idx</span><span class="p">][</span><span class="s1">&#39;RMSE_mean&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CONFIGURACIÓN ENFOCADA EN HIPERPARÁMETROS EXITOSOS:
  - Total hyperparam combos: 704
  - Cálculo: 11×2×4×4×2 = 704
  - Architecturas: 11 opciones (incluyendo las exitosas: 50, 200)
  - Activaciones: [&#39;relu&#39;, &#39;tanh&#39;]
  - Alphas: [1e-05, 0.0001, 0.001, 0.01] (incluyendo 1e-5, 1e-4, 1e-3 que funcionaron)
  - Learning rates: [0.0001, 0.0005, 0.001, 0.005]
  - Max_iter: [500, 1000]
  - Scaler: Solo StandardScaler

=== LAG 7 ===
Datos con n_steps_jump=1:
  - Número de folds: 5
  - Error al calcular tamaños: object of type &#39;numpy.int32&#39; has no len()
  - Tipo de X[0]: &lt;class &#39;numpy.ndarray&#39;&gt;
  - Forma de X[0]: (337, 7)

  Procesando Fold 1/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2121
    Mejor config: {&#39;hidden_layer_sizes&#39;: (200, 100), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.001, &#39;learning_rate_init&#39;: 0.001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1614, RMSE=0.2146, MAPE=35.58%, BDS=0.9652

  Procesando Fold 2/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2159
    Mejor config: {&#39;hidden_layer_sizes&#39;: (100, 50), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.0001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1566, RMSE=0.2143, MAPE=34.07%, BDS=0.4229

  Procesando Fold 3/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2151
    Mejor config: {&#39;hidden_layer_sizes&#39;: (20, 10), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 1e-05, &#39;learning_rate_init&#39;: 0.001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1590, RMSE=0.2138, MAPE=33.91%, BDS=0.6816

  Procesando Fold 4/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.1968
    Mejor config: {&#39;hidden_layer_sizes&#39;: (50,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.0005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1497, RMSE=0.1947, MAPE=34.14%, BDS=0.9055

  Procesando Fold 5/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2607
    Mejor config: {&#39;hidden_layer_sizes&#39;: (50,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.001, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1499, RMSE=0.2000, MAPE=33.15%, BDS=0.0995

--- RESUMEN LAG 7 ---
 Mejor config (moda): {&#39;hidden_layer_sizes&#39;: (200, 100), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.001, &#39;learning_rate_init&#39;: 0.001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
 MAE:  0.1553 ± 0.0048
 MSE:  0.0455 ± 0.0035
 RMSE: 0.2075 ± 0.0084
 MAPE: 34.17 ± 0.79%
 BDS:  0.6149 ± 0.3206

=== LAG 14 ===
Datos con n_steps_jump=1:
  - Número de folds: 5
  - Error al calcular tamaños: object of type &#39;numpy.int32&#39; has no len()
  - Tipo de X[0]: &lt;class &#39;numpy.ndarray&#39;&gt;
  - Forma de X[0]: (178, 14)

  Procesando Fold 1/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.1868
    Mejor config: {&#39;hidden_layer_sizes&#39;: (30,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.2126, RMSE=0.4327, MAPE=36.57%, BDS=0.2090

  Procesando Fold 2/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.1891
    Mejor config: {&#39;hidden_layer_sizes&#39;: (200, 100), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 1e-05, &#39;learning_rate_init&#39;: 0.001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1934, RMSE=0.3735, MAPE=36.13%, BDS=0.1542

  Procesando Fold 3/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2035
    Mejor config: {&#39;hidden_layer_sizes&#39;: (30,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.0001, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1787, RMSE=0.3332, MAPE=33.95%, BDS=0.6716

  Procesando Fold 4/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2113
    Mejor config: {&#39;hidden_layer_sizes&#39;: (100, 50), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.0005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1758, RMSE=0.3098, MAPE=33.92%, BDS=0.7114

  Procesando Fold 5/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2191
    Mejor config: {&#39;hidden_layer_sizes&#39;: (100, 50), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.0001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1612, RMSE=0.2079, MAPE=38.78%, BDS=0.9254

--- RESUMEN LAG 14 ---
 Mejor config (moda): {&#39;hidden_layer_sizes&#39;: (30,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
 MAE:  0.1843 ± 0.0175
 MSE:  0.1339 ± 0.0533
 RMSE: 0.3314 ± 0.0745
 MAPE: 35.87 ± 1.82%
 BDS:  0.5343 ± 0.3012

=== LAG 21 ===
Datos con n_steps_jump=1:
  - Número de folds: 5
  - Error al calcular tamaños: object of type &#39;numpy.int32&#39; has no len()
  - Tipo de X[0]: &lt;class &#39;numpy.ndarray&#39;&gt;
  - Forma de X[0]: (121, 21)

  Procesando Fold 1/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.1863
    Mejor config: {&#39;hidden_layer_sizes&#39;: (10,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 1e-05, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1585, RMSE=0.1984, MAPE=43.82%, BDS=0.2338

  Procesando Fold 2/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2102
    Mejor config: {&#39;hidden_layer_sizes&#39;: (200, 100), &#39;activation&#39;: &#39;tanh&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.0001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1582, RMSE=0.1982, MAPE=42.71%, BDS=0.9652

  Procesando Fold 3/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2152
    Mejor config: {&#39;hidden_layer_sizes&#39;: (200,), &#39;activation&#39;: &#39;tanh&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1554, RMSE=0.1973, MAPE=41.36%, BDS=0.2935

  Procesando Fold 4/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2294
    Mejor config: {&#39;hidden_layer_sizes&#39;: (100, 50), &#39;activation&#39;: &#39;tanh&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.0001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1617, RMSE=0.2041, MAPE=38.46%, BDS=1.0000

  Procesando Fold 5/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2199
    Mejor config: {&#39;hidden_layer_sizes&#39;: (50,), &#39;activation&#39;: &#39;tanh&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.0005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1828, RMSE=0.2263, MAPE=44.21%, BDS=1.0000

--- RESUMEN LAG 21 ---
 Mejor config (moda): {&#39;hidden_layer_sizes&#39;: (10,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 1e-05, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
 MAE:  0.1633 ± 0.0100
 MSE:  0.0437 ± 0.0043
 RMSE: 0.2048 ± 0.0110
 MAPE: 42.11 ± 2.08%
 BDS:  0.6985 ± 0.3558

=== LAG 28 ===
Datos con n_steps_jump=1:
  - Número de folds: 5
  - Error al calcular tamaños: object of type &#39;numpy.int32&#39; has no len()
  - Tipo de X[0]: &lt;class &#39;numpy.ndarray&#39;&gt;
  - Forma de X[0]: (91, 28)

  Procesando Fold 1/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2251
    Mejor config: {&#39;hidden_layer_sizes&#39;: (30, 15), &#39;activation&#39;: &#39;tanh&#39;, &#39;alpha&#39;: 0.001, &#39;learning_rate_init&#39;: 0.0005, &#39;max_iter&#39;: 1000, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1568, RMSE=0.1969, MAPE=36.63%, BDS=0.4925

  Procesando Fold 2/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2607
    Mejor config: {&#39;hidden_layer_sizes&#39;: (100,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.0001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1917, RMSE=0.2461, MAPE=41.55%, BDS=1.0000

  Procesando Fold 3/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2550
    Mejor config: {&#39;hidden_layer_sizes&#39;: (200,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.0005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1893, RMSE=0.2459, MAPE=39.38%, BDS=0.2438

  Procesando Fold 4/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2653
    Mejor config: {&#39;hidden_layer_sizes&#39;: (200, 100), &#39;activation&#39;: &#39;tanh&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1816, RMSE=0.2307, MAPE=37.56%, BDS=0.6418

  Procesando Fold 5/5...
    Evaluando config 1/704... (0.0%)
    Evaluando config 51/704... (7.1%)
    Evaluando config 101/704... (14.2%)
    Evaluando config 151/704... (21.3%)
    Evaluando config 201/704... (28.4%)
    Evaluando config 251/704... (35.5%)
    Evaluando config 301/704... (42.6%)
    Evaluando config 351/704... (49.7%)
    Evaluando config 401/704... (56.8%)
    Evaluando config 451/704... (63.9%)
    Evaluando config 501/704... (71.0%)
    Evaluando config 551/704... (78.1%)
    Evaluando config 601/704... (85.2%)
    Evaluando config 651/704... (92.3%)
    Evaluando config 701/704... (99.4%)
    Mejor RMSE validación: 0.2708
    Mejor config: {&#39;hidden_layer_sizes&#39;: (20, 10), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 1e-05, &#39;learning_rate_init&#39;: 0.001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}
    Test final: MAE=0.1897, RMSE=0.2440, MAPE=46.93%, BDS=0.6368

--- RESUMEN LAG 28 ---
 Mejor config (moda): {&#39;hidden_layer_sizes&#39;: (30, 15), &#39;activation&#39;: &#39;tanh&#39;, &#39;alpha&#39;: 0.001, &#39;learning_rate_init&#39;: 0.0005, &#39;max_iter&#39;: 1000, &#39;scaler&#39;: &#39;standard&#39;}
 MAE:  0.1818 ± 0.0130
 MSE:  0.0560 ± 0.0086
 RMSE: 0.2327 ± 0.0188
 MAPE: 40.41 ± 3.67%
 BDS:  0.6030 ± 0.2456

============================================================
RESUMEN FINAL COMPARATIVO (n_steps_jump=1)
============================================================
 Lag                                                                                                                                Best_cfg_mode  MAE_mean  MAE_std  MSE_mean  MSE_std  RMSE_mean  RMSE_std  MAPE_mean  MAPE_std  BDS_mean  BDS_std
   7 {&#39;hidden_layer_sizes&#39;: (200, 100), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.001, &#39;learning_rate_init&#39;: 0.001, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}  0.155308 0.004754  0.045511 0.003523   0.207478  0.008426  34.169668  0.787949  0.614925 0.320648
  14       {&#39;hidden_layer_sizes&#39;: (30,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 0.01, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}  0.184337 0.017457  0.133920 0.053325   0.331413  0.074518  35.871253  1.817870  0.534328 0.301159
  21      {&#39;hidden_layer_sizes&#39;: (10,), &#39;activation&#39;: &#39;relu&#39;, &#39;alpha&#39;: 1e-05, &#39;learning_rate_init&#39;: 0.005, &#39;max_iter&#39;: 500, &#39;scaler&#39;: &#39;standard&#39;}  0.163318 0.009954  0.043669 0.004287   0.204845  0.010978  42.112820  2.076459  0.698507 0.355763
  28 {&#39;hidden_layer_sizes&#39;: (30, 15), &#39;activation&#39;: &#39;tanh&#39;, &#39;alpha&#39;: 0.001, &#39;learning_rate_init&#39;: 0.0005, &#39;max_iter&#39;: 1000, &#39;scaler&#39;: &#39;standard&#39;}  0.181783 0.012972  0.056029 0.008574   0.232718  0.018798  40.411510  3.668892  0.602985 0.245560

COMPUTACIÓN COMPLETADA:
  - Configuraciones evaluadas: 704 por fold
  - Total evaluaciones aproximadas: avg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_foldsavg_folds
  - Reducción vs original: 47.6% menos configuraciones
  - Uso de datos: Máximo (n_steps_jump=1)

MEJOR LAG: 21 (RMSE promedio: 0.2048)
</pre></div>
</div>
</div>
</div>
<p>ya que no tiene un alto costo computacional por la relativamente pequena cantidad de datos, fuimos capaces de probar una gran cantidad de hiperparametros con la densidad maxima es decir n_jumps=1.
podemos observar un BDS que no rechaza la hipotesis nula de independenica en ningn caso, es decir no hay evidencia estadisticamente significativa como para afirmar que haya dependecia en la serie temporal.</p>
<p>estos resultados si bien buenos podriamos buscar en otros modelos mejor capacidad de prediccion, especialmente para ventanas de aprendizaje mas grandes, una opcion podria ser lstm.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#lstm good largo nsteps1</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.optimizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tsxv.splitTrainValTest</span><span class="w"> </span><span class="kn">import</span> <span class="n">split_train_val_test_groupKFold</span>

<span class="c1"># -------- utils --------</span>
<span class="k">def</span><span class="w"> </span><span class="nf">mape</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)))</span> <span class="o">*</span> <span class="mf">100.0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_lstm</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
        <span class="n">return_seq</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># return_sequences True si no es la última capa</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                       <span class="n">return_sequences</span><span class="o">=</span><span class="n">return_seq</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">dropout</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_steps_out</span><span class="p">))</span>  <span class="c1"># salida multistep</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">),</span> <span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># -------- datos --------</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;btc_1d_data_2018_to_2025.csv&#39;</span><span class="p">)</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[[</span><span class="s1">&#39;Open time&#39;</span><span class="p">,</span> <span class="s1">&#39;Close&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">btc</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;Open time&#39;</span><span class="p">:</span> <span class="s1">&#39;Date&#39;</span><span class="p">})</span>
<span class="n">btc</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">btc</span><span class="p">[</span><span class="s1">&#39;LogReturn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">btc</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span> <span class="o">/</span> <span class="n">btc</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">btc</span><span class="p">[</span><span class="s1">&#39;Volatility&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[</span><span class="s1">&#39;LogReturn&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">365</span><span class="p">)</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">btc</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">volatility_full</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[</span><span class="s1">&#39;Volatility&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># -------- params --------</span>
<span class="n">n_steps_out</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">n_steps_jump</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">lags_to_try</span> <span class="o">=</span> <span class="p">[</span><span class="mi">21</span><span class="p">,</span> <span class="mi">28</span><span class="p">]</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">units</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]:</span>
    <span class="k">for</span> <span class="n">dropout</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]:</span>
        <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0005</span><span class="p">]:</span>
            <span class="k">for</span> <span class="n">batch_size</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">]:</span>
                <span class="k">for</span> <span class="n">n_layers</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]:</span>  <span class="c1"># 1 o 2 capas LSTM</span>
                    <span class="n">param_grid</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                        <span class="s2">&quot;units&quot;</span><span class="p">:</span> <span class="n">units</span><span class="p">,</span>
                        <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">dropout</span><span class="p">,</span>
                        <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span>
                        <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
                        <span class="s2">&quot;n_layers&quot;</span><span class="p">:</span> <span class="n">n_layers</span>
                    <span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total configs: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># -------- experimento --------</span>
<span class="k">for</span> <span class="n">n_steps_in</span> <span class="ow">in</span> <span class="n">lags_to_try</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">=== LAG </span><span class="si">{</span><span class="n">n_steps_in</span><span class="si">}</span><span class="s2"> con LSTM ===&quot;</span><span class="p">)</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">Xcv</span><span class="p">,</span> <span class="n">ycv</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">split_train_val_test_groupKFold</span><span class="p">(</span>
        <span class="n">volatility_full</span><span class="p">,</span>
        <span class="n">n_steps_in</span><span class="p">,</span>
        <span class="n">n_steps_out</span><span class="p">,</span>
        <span class="n">n_steps_jump</span>
    <span class="p">)</span>

    <span class="n">folds_stats</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">--- Fold </span><span class="si">{</span><span class="n">fold</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> ---&quot;</span><span class="p">)</span>
        <span class="n">Xtr</span><span class="p">,</span> <span class="n">ytr</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">fold</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span>
        <span class="n">Xval</span><span class="p">,</span> <span class="n">yval</span> <span class="o">=</span> <span class="n">Xcv</span><span class="p">[</span><span class="n">fold</span><span class="p">],</span> <span class="n">ycv</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span>
        <span class="n">Xte</span><span class="p">,</span> <span class="n">yte</span> <span class="o">=</span> <span class="n">Xtest</span><span class="p">[</span><span class="n">fold</span><span class="p">],</span> <span class="n">ytest</span><span class="p">[</span><span class="n">fold</span><span class="p">]</span>

        <span class="c1"># Escalado</span>
        <span class="n">scaler_x</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        <span class="n">scaler_y</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
        <span class="n">Xtr_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Xtr</span><span class="p">)</span>
        <span class="n">ytr_s</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">ytr</span><span class="p">)</span>
        <span class="n">Xval_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xval</span><span class="p">)</span>
        <span class="n">yval_s</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">yval</span><span class="p">)</span>
        <span class="n">Xte_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xte</span><span class="p">)</span>

        <span class="c1"># reshape para LSTM [samples, timesteps, features]</span>
        <span class="n">Xtr_s</span> <span class="o">=</span> <span class="n">Xtr_s</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Xtr_s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xtr_s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">Xval_s</span> <span class="o">=</span> <span class="n">Xval_s</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Xval_s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xval_s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">Xte_s</span> <span class="o">=</span> <span class="n">Xte_s</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Xte_s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xte_s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># búsqueda manual</span>
        <span class="n">best_cfg</span><span class="p">,</span> <span class="n">best_rmse</span><span class="p">,</span> <span class="n">best_model</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">cfg</span> <span class="ow">in</span> <span class="n">param_grid</span><span class="p">:</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">build_lstm</span><span class="p">((</span><span class="n">n_steps_in</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;units&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtr_s</span><span class="p">,</span> <span class="n">ytr_s</span><span class="p">,</span>
                      <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">Xval_s</span><span class="p">,</span> <span class="n">yval_s</span><span class="p">),</span>
                      <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">yval_hat</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xval_s</span><span class="p">))</span>
            <span class="n">rmse_val</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yval</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yval_hat</span><span class="p">[:,</span><span class="n">h</span><span class="p">]))</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps_out</span><span class="p">)])</span>
            <span class="k">if</span> <span class="n">rmse_val</span> <span class="o">&lt;</span> <span class="n">best_rmse</span><span class="p">:</span>
                <span class="n">best_rmse</span><span class="p">,</span> <span class="n">best_cfg</span><span class="p">,</span> <span class="n">best_model</span> <span class="o">=</span> <span class="n">rmse_val</span><span class="p">,</span> <span class="n">cfg</span><span class="p">,</span> <span class="n">model</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best config fold </span><span class="si">{</span><span class="n">fold</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">best_cfg</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># retrain con train+val</span>
        <span class="n">Xtrain_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Xval</span><span class="p">])</span>
        <span class="n">ytrain_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">ytr</span><span class="p">,</span> <span class="n">yval</span><span class="p">])</span>
        <span class="n">Xtrain_full_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Xtrain_full</span><span class="p">)</span>
        <span class="n">ytrain_full_s</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">ytrain_full</span><span class="p">)</span>
        <span class="n">Xtrain_full_s</span> <span class="o">=</span> <span class="n">Xtrain_full_s</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Xtrain_full_s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xtrain_full_s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

        <span class="n">final_model</span> <span class="o">=</span> <span class="n">build_lstm</span><span class="p">((</span><span class="n">n_steps_in</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;units&quot;</span><span class="p">],</span> <span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">],</span> <span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">],</span> <span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span>
        <span class="n">final_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_full_s</span><span class="p">,</span> <span class="n">ytrain_full_s</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">best_cfg</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># test</span>
        <span class="n">Xte_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xte</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Xte</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xte</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">yte_hat</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">final_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte_s</span><span class="p">))</span>

        <span class="c1"># métricas</span>
        <span class="n">mae_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yte</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yte_hat</span><span class="p">[:,</span><span class="n">h</span><span class="p">])</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps_out</span><span class="p">)])</span>
        <span class="n">mse_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yte</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yte_hat</span><span class="p">[:,</span><span class="n">h</span><span class="p">])</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps_out</span><span class="p">)])</span>
        <span class="n">rmse_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_mean</span><span class="p">)</span>
        <span class="n">mape_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">mape</span><span class="p">(</span><span class="n">yte</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yte_hat</span><span class="p">[:,</span><span class="n">h</span><span class="p">])</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps_out</span><span class="p">)])</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fold </span><span class="si">{</span><span class="n">fold</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> Test: MAE=</span><span class="si">{</span><span class="n">mae_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, RMSE=</span><span class="si">{</span><span class="n">rmse_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, MAPE=</span><span class="si">{</span><span class="n">mape_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

        <span class="n">folds_stats</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;fold&quot;</span><span class="p">:</span> <span class="n">fold</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;best_cfg&quot;</span><span class="p">:</span> <span class="n">best_cfg</span><span class="p">,</span>
            <span class="s2">&quot;MAE&quot;</span><span class="p">:</span> <span class="n">mae_mean</span><span class="p">,</span>
            <span class="s2">&quot;MSE&quot;</span><span class="p">:</span> <span class="n">mse_mean</span><span class="p">,</span>
            <span class="s2">&quot;RMSE&quot;</span><span class="p">:</span> <span class="n">rmse_mean</span><span class="p">,</span>
            <span class="s2">&quot;MAPE&quot;</span><span class="p">:</span> <span class="n">mape_mean</span>
        <span class="p">})</span>

    <span class="n">df_folds</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">folds_stats</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Resumen LAG </span><span class="si">{</span><span class="n">n_steps_in</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">df_folds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Total configs: 72

=== LAG 21 con LSTM ===

--- Fold 1 ---
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 192ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 117ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 189ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 119ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 208ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 211ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 189ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 137ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 115ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 203ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 194ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 189ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 129ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 201ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 121ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 215ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 119ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 197ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 194ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 112ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 193ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 190ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 194ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 116ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 192ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 191ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 191ms/step
Best config fold 1: {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;batch_size&#39;: 32, &#39;n_layers&#39;: 1}
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
Fold 1 Test: MAE=0.1596, RMSE=0.2193, MAPE=39.78%

--- Fold 2 ---
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 123ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 187ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 115ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 192ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 121ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 197ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 192ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 152ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 202ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 191ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 116ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 199ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 114ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 195ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 112ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 196ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 191ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 117ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 187ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 197ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 218ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 150ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 191ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 121ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 207ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 128ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 170ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
Best config fold 2: {&#39;units&#39;: 64, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.0005, &#39;batch_size&#39;: 64, &#39;n_layers&#39;: 1}
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
Fold 2 Test: MAE=0.1697, RMSE=0.2167, MAPE=47.16%

--- Fold 3 ---
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 175ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 172ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 98ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 171ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 171ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 96ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 171ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 189ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 172ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 97ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 175ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 98ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 98ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 175ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 116ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 172ms/step
Best config fold 3: {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.0005, &#39;batch_size&#39;: 64, &#39;n_layers&#39;: 1}
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
Fold 3 Test: MAE=0.1758, RMSE=0.2207, MAPE=45.87%

--- Fold 4 ---
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 172ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 171ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 171ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 172ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 171ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 171ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 168ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 171ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 172ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 100ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 173ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 191ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 187ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 114ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 112ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 192ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 192ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 113ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 187ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 113ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 190ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 115ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 188ms/step
Best config fold 4: {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.0005, &#39;batch_size&#39;: 32, &#39;n_layers&#39;: 1}
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
Fold 4 Test: MAE=0.1684, RMSE=0.2098, MAPE=41.53%

--- Fold 5 ---
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 113ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 189ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 113ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 188ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 175ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 175ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
Best config fold 5: {&#39;units&#39;: 128, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;batch_size&#39;: 64, &#39;n_layers&#39;: 2}
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
Fold 5 Test: MAE=0.2150, RMSE=0.2730, MAPE=51.00%

Resumen LAG 21
   fold                                           best_cfg       MAE  \
0     1  {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;ba...  0.159583   
1     2  {&#39;units&#39;: 64, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.0005, &#39;b...  0.169683   
2     3  {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.0005, &#39;b...  0.175806   
3     4  {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.0005, &#39;b...  0.168363   
4     5  {&#39;units&#39;: 128, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;b...  0.214964   

        MSE      RMSE       MAPE  
0  0.048083  0.219279  39.780273  
1  0.046966  0.216717  47.163518  
2  0.048710  0.220705  45.867195  
3  0.044000  0.209761  41.534021  
4  0.074504  0.272953  51.001217  

=== LAG 28 con LSTM ===

--- Fold 1 ---
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 175ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 175ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 137ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 199ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 114ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 201ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
Best config fold 1: {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;batch_size&#39;: 32, &#39;n_layers&#39;: 1}
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
Fold 1 Test: MAE=0.1565, RMSE=0.1943, MAPE=34.04%

--- Fold 2 ---
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 196ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 187ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 112ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 187ms/step
Best config fold 2: {&#39;units&#39;: 128, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;batch_size&#39;: 32, &#39;n_layers&#39;: 1}
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
Fold 2 Test: MAE=0.2096, RMSE=0.2602, MAPE=45.06%

--- Fold 3 ---
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 175ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 122ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 187ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 187ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 114ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
Best config fold 3: {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;batch_size&#39;: 32, &#39;n_layers&#39;: 1}
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
Fold 3 Test: MAE=0.1965, RMSE=0.2433, MAPE=41.60%

--- Fold 4 ---
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 177ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 181ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 191ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 188ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 190ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 112ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 189ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 189ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 188ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 191ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 188ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 190ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 189ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 192ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 190ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 196ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
Best config fold 4: {&#39;units&#39;: 128, &#39;dropout&#39;: 0.2, &#39;lr&#39;: 0.001, &#39;batch_size&#39;: 32, &#39;n_layers&#39;: 1}
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
Fold 4 Test: MAE=0.2302, RMSE=0.2975, MAPE=48.54%

--- Fold 5 ---
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 174ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 178ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 176ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 172ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 114ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 105ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 179ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 188ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 112ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 180ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 182ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 106ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 107ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 242ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 112ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 186ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 110ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 111ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 113ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 184ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 112ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 185ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 183ms/step
Best config fold 5: {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.0005, &#39;batch_size&#39;: 32, &#39;n_layers&#39;: 1}
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 104ms/step
Fold 5 Test: MAE=0.2141, RMSE=0.2601, MAPE=54.44%

Resumen LAG 28
   fold                                           best_cfg       MAE  \
0     1  {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;ba...  0.156451   
1     2  {&#39;units&#39;: 128, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;b...  0.209594   
2     3  {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.001, &#39;ba...  0.196506   
3     4  {&#39;units&#39;: 128, &#39;dropout&#39;: 0.2, &#39;lr&#39;: 0.001, &#39;b...  0.230197   
4     5  {&#39;units&#39;: 32, &#39;dropout&#39;: 0.5, &#39;lr&#39;: 0.0005, &#39;b...  0.214105   

        MSE      RMSE       MAPE  
0  0.037759  0.194317  34.039123  
1  0.067707  0.260207  45.056798  
2  0.059203  0.243317  41.600887  
3  0.088506  0.297499  48.537819  
4  0.067643  0.260082  54.438200  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#lstm arreglo summary</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># --- Insert your fold results here ---</span>
<span class="c1"># Example: replace with the exact DataFrames or lists of dicts you already have.</span>

<span class="c1"># Lag 21 results (example from your message)</span>
<span class="n">data_21</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;MSE&quot;</span><span class="p">:</span>  <span class="p">[</span><span class="mf">0.093978</span><span class="p">,</span> <span class="mf">0.144438</span><span class="p">,</span> <span class="mf">0.051106</span><span class="p">,</span> <span class="mf">0.099004</span><span class="p">,</span> <span class="mf">0.057579</span><span class="p">],</span>
    <span class="s2">&quot;RMSE&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.306559</span><span class="p">,</span> <span class="mf">0.380050</span><span class="p">,</span> <span class="mf">0.226067</span><span class="p">,</span> <span class="mf">0.314649</span><span class="p">,</span> <span class="mf">0.239957</span><span class="p">],</span>
    <span class="s2">&quot;MAPE&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">53.613824</span><span class="p">,</span> <span class="mf">69.903833</span><span class="p">,</span> <span class="mf">50.745610</span><span class="p">,</span> <span class="mf">54.928077</span><span class="p">,</span> <span class="mf">28.395565</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">df21</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_21</span><span class="p">)</span>

<span class="c1"># Lag 28 results (example from your message)</span>
<span class="n">data_28</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;MSE&quot;</span><span class="p">:</span>  <span class="p">[</span><span class="mf">0.134804</span><span class="p">,</span> <span class="mf">0.107746</span><span class="p">,</span> <span class="mf">0.064221</span><span class="p">,</span> <span class="mf">0.048260</span><span class="p">,</span> <span class="mf">0.602563</span><span class="p">],</span>
    <span class="s2">&quot;RMSE&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.367156</span><span class="p">,</span> <span class="mf">0.328247</span><span class="p">,</span> <span class="mf">0.253419</span><span class="p">,</span> <span class="mf">0.219681</span><span class="p">,</span> <span class="mf">0.776249</span><span class="p">],</span>
    <span class="s2">&quot;MAPE&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">50.138153</span><span class="p">,</span> <span class="mf">51.147897</span><span class="p">,</span> <span class="mf">27.707450</span><span class="p">,</span> <span class="mf">50.268408</span><span class="p">,</span> <span class="mf">60.848165</span><span class="p">]</span>
<span class="p">}</span>
<span class="n">df28</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data_28</span><span class="p">)</span>

<span class="c1"># --- Function to compute mean and std for each metric ---</span>
<span class="k">def</span><span class="w"> </span><span class="nf">summarize</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">lag</span><span class="p">):</span>
    <span class="n">summary</span> <span class="o">=</span> <span class="p">{</span> <span class="s2">&quot;Lag&quot;</span><span class="p">:</span> <span class="n">lag</span> <span class="p">}</span>
    <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s2">_mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
        <span class="n">summary</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s2">_std&quot;</span><span class="p">]</span>  <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">metric</span><span class="p">]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">summary</span>

<span class="c1"># Apply to both lags</span>
<span class="n">summary_21</span> <span class="o">=</span> <span class="n">summarize</span><span class="p">(</span><span class="n">df21</span><span class="p">,</span> <span class="mi">21</span><span class="p">)</span>
<span class="n">summary_28</span> <span class="o">=</span> <span class="n">summarize</span><span class="p">(</span><span class="n">df28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="n">df_summary</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">summary_21</span><span class="p">,</span> <span class="n">summary_28</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">===== LSTM Fold Summary (mean ± std) =====&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_summary</span><span class="o">.</span><span class="n">to_string</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>===== LSTM Fold Summary (mean ± std) =====
 Lag  MSE_mean  MSE_std  RMSE_mean  RMSE_std  MAPE_mean  MAPE_std
  21  0.089221 0.037487   0.293456  0.062295  51.517382 14.910596
  28  0.191519 0.232336   0.388950  0.224266  48.022015 12.211543
</pre></div>
</div>
</div>
</div>
<p>pero en este caso, a pesar de tener un tiempo de computacion mayor no fue capaz de superar las metricas de el modelo MLP, por lo anterior nos mantendremos usando MLP con los 4 tamanos de lag.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># corregir hiperparam Autocontained: retrain only using provided best hyperparams, collect metrics, produce plots &amp; CSVs.</span>
<span class="c1"># Requirements: numpy, pandas, sklearn, tensorflow (keras), matplotlib, tsxv split function available.</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;TF_CPP_MIN_LOG_LEVEL&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;2&#39;</span>

<span class="c1"># ML / preprocessing</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.neural_network</span><span class="w"> </span><span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>

<span class="c1"># Keras LSTM</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">tensorflow</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">tf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.optimizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>

<span class="c1"># plotting</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># timeseries split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tsxv.splitTrainValTest</span><span class="w"> </span><span class="kn">import</span> <span class="n">split_train_val_test_groupKFold</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Utils</span>
<span class="c1"># ---------------------------</span>
<span class="k">def</span><span class="w"> </span><span class="nf">mape</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">+</span> <span class="mf">1e-12</span><span class="p">)))</span> <span class="o">*</span> <span class="mf">100.0</span>

<span class="k">def</span><span class="w"> </span><span class="nf">choose_scaler</span><span class="p">(</span><span class="n">kind</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">StandardScaler</span><span class="p">()</span> <span class="k">if</span> <span class="n">kind</span> <span class="o">==</span> <span class="s2">&quot;standard&quot;</span> <span class="k">else</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">rmse_per_horiz</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">y_pred</span><span class="p">[:,</span><span class="n">h</span><span class="p">]))</span> <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">y_true</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])])</span>

<span class="k">def</span><span class="w"> </span><span class="nf">bds_test</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">max_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">eps_factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Return DataFrame indexed by m with columns statistic and p_value. Handles short samples.&quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">_np</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">_pd</span>
    <span class="n">_np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([(</span><span class="mi">2</span><span class="p">,</span> <span class="n">_np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">_np</span><span class="o">.</span><span class="n">nan</span><span class="p">)],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span><span class="s1">&#39;p_value&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>
    <span class="n">eps</span> <span class="o">=</span> <span class="n">eps_factor</span> <span class="o">*</span> <span class="n">_np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">embed</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">m</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="n">m</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">correlation_integral</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">eps</span><span class="p">):</span>
        <span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">N</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.0</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="n">_np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">_np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">eps</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">count</span> <span class="o">/</span> <span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_dim</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">Xm</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
        <span class="n">X1</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">Cm</span> <span class="o">=</span> <span class="n">correlation_integral</span><span class="p">(</span><span class="n">Xm</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">C1</span> <span class="o">=</span> <span class="n">correlation_integral</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
        <span class="n">bds_stat</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">Cm</span> <span class="o">-</span> <span class="n">C1</span><span class="o">**</span><span class="n">m</span><span class="p">)</span>

        <span class="n">boot_stats</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_bootstrap</span><span class="p">):</span>
            <span class="n">shuffled</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span>
            <span class="n">Xm_boot</span> <span class="o">=</span> <span class="n">embed</span><span class="p">(</span><span class="n">shuffled</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
            <span class="n">Cmb</span> <span class="o">=</span> <span class="n">correlation_integral</span><span class="p">(</span><span class="n">Xm_boot</span><span class="p">,</span> <span class="n">eps</span><span class="p">)</span>
            <span class="n">C1b</span> <span class="o">=</span> <span class="n">correlation_integral</span><span class="p">(</span><span class="n">embed</span><span class="p">(</span><span class="n">shuffled</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">eps</span><span class="p">)</span>
            <span class="n">boot_stats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">Cmb</span> <span class="o">-</span> <span class="n">C1b</span><span class="o">**</span><span class="n">m</span><span class="p">))</span>
        <span class="n">boot_stats</span> <span class="o">=</span> <span class="n">_np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">boot_stats</span><span class="p">)</span>
        <span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span> <span class="n">_np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">_np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">boot_stats</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">_np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">bds_stat</span><span class="p">))</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_bootstrap</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">bds_stat</span><span class="p">,</span> <span class="n">p_value</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">,</span><span class="s1">&#39;statistic&#39;</span><span class="p">,</span><span class="s1">&#39;p_value&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;m&#39;</span><span class="p">)</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Load data (exactly as requested)</span>
<span class="c1"># ---------------------------</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;btc_1d_data_2018_to_2025.csv&quot;</span><span class="p">)</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[[</span><span class="s2">&quot;Open time&quot;</span><span class="p">,</span> <span class="s2">&quot;Close&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">btc</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;Open time&quot;</span><span class="p">:</span> <span class="s2">&quot;Date&quot;</span><span class="p">})</span>
<span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">btc</span><span class="p">[</span><span class="s2">&quot;LogReturn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Close&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">window_size</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Volatility&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[</span><span class="s2">&quot;LogReturn&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="n">window_size</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">()</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">365</span><span class="p">)</span>
<span class="n">btc</span> <span class="o">=</span> <span class="n">btc</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s2">&quot;Date&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">dropna</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">volatility_full</span> <span class="o">=</span> <span class="n">btc</span><span class="p">[</span><span class="s2">&quot;Volatility&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># create directories</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;notebooks/figs/mlp&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;notebooks/figs/lstm&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;results/mlp&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;results/lstm&quot;</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Best hyperparams (you provided these earlier)</span>
<span class="c1"># ---------------------------</span>
<span class="n">best_cfgs_mlp</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">7</span><span class="p">:</span>  <span class="p">{</span><span class="s1">&#39;hidden_layer_sizes&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,),</span> <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">1e-05</span><span class="p">,</span> <span class="s1">&#39;learning_rate_init&#39;</span><span class="p">:</span> <span class="mf">0.005</span><span class="p">,</span> <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span> <span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="s1">&#39;standard&#39;</span><span class="p">},</span>
    <span class="mi">14</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;hidden_layer_sizes&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,),</span> <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="s1">&#39;tanh&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">,</span> <span class="s1">&#39;learning_rate_init&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span> <span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="s1">&#39;standard&#39;</span><span class="p">},</span>
    <span class="mi">21</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;hidden_layer_sizes&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">50</span><span class="p">,),</span> <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.0001</span><span class="p">,</span> <span class="s1">&#39;learning_rate_init&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span> <span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="s1">&#39;standard&#39;</span><span class="p">},</span>
    <span class="mi">28</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;hidden_layer_sizes&#39;</span><span class="p">:</span> <span class="p">(</span><span class="mi">200</span><span class="p">,),</span> <span class="s1">&#39;activation&#39;</span><span class="p">:</span> <span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;learning_rate_init&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;max_iter&#39;</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span> <span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="s1">&#39;standard&#39;</span><span class="p">},</span>
<span class="p">}</span>

<span class="n">best_cfgs_lstm</span> <span class="o">=</span> <span class="p">{</span>
    <span class="mi">21</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;units&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.0005</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;n_layers&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
    <span class="mi">28</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;units&#39;</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;dropout&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="mi">32</span><span class="p">,</span> <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> <span class="s1">&#39;n_layers&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
<span class="p">}</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Functions to build &amp; fit final models (train on train+val)</span>
<span class="c1"># ---------------------------</span>
<span class="k">def</span><span class="w"> </span><span class="nf">build_and_fit_mlp</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
    <span class="n">scaler_x</span> <span class="o">=</span> <span class="n">choose_scaler</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span><span class="s2">&quot;standard&quot;</span><span class="p">))</span>
    <span class="n">scaler_y</span> <span class="o">=</span> <span class="n">choose_scaler</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scaler&quot;</span><span class="p">,</span><span class="s2">&quot;standard&quot;</span><span class="p">))</span>
    <span class="n">Xs</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">hidden_layer_sizes</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">],</span>
                         <span class="n">activation</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
                         <span class="n">alpha</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;alpha&quot;</span><span class="p">],</span>
                         <span class="n">learning_rate_init</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;learning_rate_init&quot;</span><span class="p">],</span>
                         <span class="n">max_iter</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;max_iter&quot;</span><span class="p">],</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">scaler_x</span><span class="p">,</span> <span class="n">scaler_y</span>

<span class="k">def</span><span class="w"> </span><span class="nf">build_and_fit_lstm</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cfg</span><span class="p">):</span>
    <span class="c1"># scaler</span>
    <span class="n">scaler_x</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
    <span class="n">scaler_y</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
    <span class="n">Xs</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
    <span class="c1"># reshape for LSTM</span>
    <span class="n">Xs_r</span> <span class="o">=</span> <span class="n">Xs</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># build model</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;n_layers&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;units&quot;</span><span class="p">],</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">Xs_r</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;units&quot;</span><span class="p">],</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">Xs_r</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">),</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]))</span>
        <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;units&quot;</span><span class="p">],</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">ys</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;lr&quot;</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;mse&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs_r</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;epochs&quot;</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">scaler_x</span><span class="p">,</span> <span class="n">scaler_y</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Run retrain-only pipeline: MLP (lags 7,14,21,28), LSTM (21,28)</span>
<span class="c1"># For each fold: retrain on train+val with best_cfg, evaluate on test, store final_model &amp; scalers for plotting</span>
<span class="c1"># ---------------------------</span>
<span class="n">n_steps_out</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">n_steps_jump</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">folds_stats_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mlp&quot;</span><span class="p">:</span> <span class="p">{},</span> <span class="s2">&quot;lstm&quot;</span><span class="p">:</span> <span class="p">{}}</span>
<span class="n">summary_rows</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;mlp&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;lstm&quot;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="c1"># Helper to summarize per-fold-&gt;summary</span>
<span class="k">def</span><span class="w"> </span><span class="nf">summarize_folds</span><span class="p">(</span><span class="n">folds_stats</span><span class="p">):</span>
    <span class="n">mae_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">f</span><span class="p">[</span><span class="s2">&quot;mae_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">mse_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">f</span><span class="p">[</span><span class="s2">&quot;mse_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">rmse_arr</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">f</span><span class="p">[</span><span class="s2">&quot;rmse_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">mape_arr</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">f</span><span class="p">[</span><span class="s2">&quot;mape_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">bds_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">f</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;bds_pval_h1&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;MAE_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mae_arr</span><span class="p">)),</span> <span class="s2">&quot;MAE_std&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mae_arr</span><span class="p">)),</span>
        <span class="s2">&quot;MSE_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mse_arr</span><span class="p">)),</span> <span class="s2">&quot;MSE_std&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mse_arr</span><span class="p">)),</span>
        <span class="s2">&quot;RMSE_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rmse_arr</span><span class="p">)),</span> <span class="s2">&quot;RMSE_std&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">rmse_arr</span><span class="p">)),</span>
        <span class="s2">&quot;MAPE_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mape_arr</span><span class="p">)),</span> <span class="s2">&quot;MAPE_std&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">mape_arr</span><span class="p">)),</span>
        <span class="s2">&quot;BDS_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">bds_arr</span><span class="p">)),</span> <span class="s2">&quot;BDS_std&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nanstd</span><span class="p">(</span><span class="n">bds_arr</span><span class="p">))</span>
    <span class="p">}</span>

<span class="c1"># --- MLP ---</span>
<span class="k">for</span> <span class="n">lag</span><span class="p">,</span> <span class="n">cfg</span> <span class="ow">in</span> <span class="n">best_cfgs_mlp</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&gt;&gt;&gt; MLP: retraining &amp; evaluating lag=</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xcvs</span><span class="p">,</span> <span class="n">ycvs</span><span class="p">,</span> <span class="n">Xtests</span><span class="p">,</span> <span class="n">ytests</span> <span class="o">=</span> <span class="n">split_train_val_test_groupKFold</span><span class="p">(</span><span class="n">volatility_full</span><span class="p">,</span> <span class="n">lag</span><span class="p">,</span> <span class="n">n_steps_out</span><span class="p">,</span> <span class="n">n_steps_jump</span><span class="p">)</span>
    <span class="n">folds_stats</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fi</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Xs</span><span class="p">)):</span>
        <span class="n">Xtr</span><span class="p">,</span> <span class="n">ytr</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">[</span><span class="n">fi</span><span class="p">],</span> <span class="n">ys</span><span class="p">[</span><span class="n">fi</span><span class="p">]</span>
        <span class="n">Xval</span><span class="p">,</span> <span class="n">yval</span> <span class="o">=</span> <span class="n">Xcvs</span><span class="p">[</span><span class="n">fi</span><span class="p">],</span> <span class="n">ycvs</span><span class="p">[</span><span class="n">fi</span><span class="p">]</span>
        <span class="n">Xte</span><span class="p">,</span> <span class="n">yte</span> <span class="o">=</span> <span class="n">Xtests</span><span class="p">[</span><span class="n">fi</span><span class="p">],</span> <span class="n">ytests</span><span class="p">[</span><span class="n">fi</span><span class="p">]</span>

        <span class="c1"># retrain on train+val</span>
        <span class="n">Xtrain_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Xval</span><span class="p">])</span>
        <span class="n">ytrain_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">ytr</span><span class="p">,</span> <span class="n">yval</span><span class="p">])</span>
        <span class="n">final_model</span><span class="p">,</span> <span class="n">scaler_x</span><span class="p">,</span> <span class="n">scaler_y</span> <span class="o">=</span> <span class="n">build_and_fit_mlp</span><span class="p">(</span><span class="n">Xtrain_full</span><span class="p">,</span> <span class="n">ytrain_full</span><span class="p">,</span> <span class="n">cfg</span><span class="p">)</span>

        <span class="c1"># predict on test</span>
        <span class="n">Xte_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xte</span><span class="p">)</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">final_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte_s</span><span class="p">))</span>
        <span class="c1"># metrics per horizon</span>
        <span class="n">per_h</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps_out</span><span class="p">):</span>
            <span class="n">mae_h</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yte</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yhat</span><span class="p">[:,</span><span class="n">h</span><span class="p">])</span>
            <span class="n">mse_h</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yte</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yhat</span><span class="p">[:,</span><span class="n">h</span><span class="p">])</span>
            <span class="n">rmse_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_h</span><span class="p">)</span>
            <span class="n">mape_h</span> <span class="o">=</span> <span class="n">mape</span><span class="p">(</span><span class="n">yte</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yhat</span><span class="p">[:,</span><span class="n">h</span><span class="p">])</span>
            <span class="n">per_h</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">mae_h</span><span class="p">,</span> <span class="n">mse_h</span><span class="p">,</span> <span class="n">rmse_h</span><span class="p">,</span> <span class="n">mape_h</span><span class="p">))</span>

        <span class="n">mae_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">per_h</span><span class="p">])</span>
        <span class="n">mse_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">per_h</span><span class="p">])</span>
        <span class="n">rmse_mean</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">per_h</span><span class="p">])</span>
        <span class="n">mape_mean</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">per_h</span><span class="p">])</span>

        <span class="c1"># bds on residuals horizon1</span>
        <span class="n">resid_h1</span> <span class="o">=</span> <span class="n">yte</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">bds_df</span> <span class="o">=</span> <span class="n">bds_test</span><span class="p">(</span><span class="n">resid_h1</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">bds_pval</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">bds_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;p_value&quot;</span><span class="p">])</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">bds_pval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

        <span class="n">folds_stats</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;fold&quot;</span><span class="p">:</span> <span class="n">fi</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;best_cfg&quot;</span><span class="p">:</span> <span class="n">cfg</span><span class="p">,</span>
            <span class="s2">&quot;final_model&quot;</span><span class="p">:</span> <span class="n">final_model</span><span class="p">,</span>
            <span class="s2">&quot;scaler_x&quot;</span><span class="p">:</span> <span class="n">scaler_x</span><span class="p">,</span>
            <span class="s2">&quot;scaler_y&quot;</span><span class="p">:</span> <span class="n">scaler_y</span><span class="p">,</span>
            <span class="s2">&quot;per_h_metrics&quot;</span><span class="p">:</span> <span class="n">per_h</span><span class="p">,</span>
            <span class="s2">&quot;mae_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">mae_mean</span><span class="p">),</span>
            <span class="s2">&quot;mse_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">mse_mean</span><span class="p">),</span>
            <span class="s2">&quot;rmse_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">rmse_mean</span><span class="p">),</span>
            <span class="s2">&quot;mape_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">mape_mean</span><span class="p">),</span>
            <span class="s2">&quot;bds_pval_h1&quot;</span><span class="p">:</span> <span class="n">bds_pval</span>
        <span class="p">})</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  fold </span><span class="si">{</span><span class="n">fi</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: RMSE=</span><span class="si">{</span><span class="n">rmse_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, MAPE=</span><span class="si">{</span><span class="n">mape_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> (saved model in memory)&quot;</span><span class="p">)</span>

    <span class="n">folds_stats_dict</span><span class="p">[</span><span class="s2">&quot;mlp&quot;</span><span class="p">][</span><span class="n">lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">folds_stats</span>
    <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_folds</span><span class="p">(</span><span class="n">folds_stats</span><span class="p">)</span>
    <span class="n">summary</span><span class="p">[</span><span class="s2">&quot;Lag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lag</span>
    <span class="n">summary</span><span class="p">[</span><span class="s2">&quot;Best_cfg_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
    <span class="n">summary_rows</span><span class="p">[</span><span class="s2">&quot;mlp&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
    <span class="c1"># save per-lag CSV</span>
    <span class="n">df_f</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;final_model&#39;</span><span class="p">,</span><span class="s1">&#39;scaler_x&#39;</span><span class="p">,</span><span class="s1">&#39;scaler_y&#39;</span><span class="p">)}</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">df_f</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;results/mlp/folds_metrics_lag</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[saved] results/mlp/folds_metrics_lag</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">.csv&quot;</span><span class="p">)</span>

<span class="c1"># --- LSTM ---</span>
<span class="k">for</span> <span class="n">lag</span><span class="p">,</span> <span class="n">cfg</span> <span class="ow">in</span> <span class="n">best_cfgs_lstm</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&gt;&gt;&gt; LSTM: retraining &amp; evaluating lag=</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xcvs</span><span class="p">,</span> <span class="n">ycvs</span><span class="p">,</span> <span class="n">Xtests</span><span class="p">,</span> <span class="n">ytests</span> <span class="o">=</span> <span class="n">split_train_val_test_groupKFold</span><span class="p">(</span><span class="n">volatility_full</span><span class="p">,</span> <span class="n">lag</span><span class="p">,</span> <span class="n">n_steps_out</span><span class="p">,</span> <span class="n">n_steps_jump</span><span class="p">)</span>
    <span class="n">folds_stats</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">fi</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Xs</span><span class="p">)):</span>
        <span class="n">Xtr</span><span class="p">,</span> <span class="n">ytr</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">[</span><span class="n">fi</span><span class="p">],</span> <span class="n">ys</span><span class="p">[</span><span class="n">fi</span><span class="p">]</span>
        <span class="n">Xval</span><span class="p">,</span> <span class="n">yval</span> <span class="o">=</span> <span class="n">Xcvs</span><span class="p">[</span><span class="n">fi</span><span class="p">],</span> <span class="n">ycvs</span><span class="p">[</span><span class="n">fi</span><span class="p">]</span>
        <span class="n">Xte</span><span class="p">,</span> <span class="n">yte</span> <span class="o">=</span> <span class="n">Xtests</span><span class="p">[</span><span class="n">fi</span><span class="p">],</span> <span class="n">ytests</span><span class="p">[</span><span class="n">fi</span><span class="p">]</span>

        <span class="c1"># retrain on train+val</span>
        <span class="n">Xtrain_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">Xtr</span><span class="p">,</span> <span class="n">Xval</span><span class="p">])</span>
        <span class="n">ytrain_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">ytr</span><span class="p">,</span> <span class="n">yval</span><span class="p">])</span>
        <span class="n">final_model</span><span class="p">,</span> <span class="n">scaler_x</span><span class="p">,</span> <span class="n">scaler_y</span> <span class="o">=</span> <span class="n">build_and_fit_lstm</span><span class="p">(</span><span class="n">Xtrain_full</span><span class="p">,</span> <span class="n">ytrain_full</span><span class="p">,</span> <span class="n">cfg</span><span class="p">)</span>

        <span class="c1"># predict on test (reshape)</span>
        <span class="n">Xte_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xte</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Xte</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xte</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">final_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte_s</span><span class="p">))</span>

        <span class="c1"># per-h metrics</span>
        <span class="n">per_h</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_steps_out</span><span class="p">):</span>
            <span class="n">mae_h</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">yte</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yhat</span><span class="p">[:,</span><span class="n">h</span><span class="p">])</span>
            <span class="n">mse_h</span> <span class="o">=</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">yte</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yhat</span><span class="p">[:,</span><span class="n">h</span><span class="p">])</span>
            <span class="n">rmse_h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mse_h</span><span class="p">)</span>
            <span class="n">mape_h</span> <span class="o">=</span> <span class="n">mape</span><span class="p">(</span><span class="n">yte</span><span class="p">[:,</span><span class="n">h</span><span class="p">],</span> <span class="n">yhat</span><span class="p">[:,</span><span class="n">h</span><span class="p">])</span>
            <span class="n">per_h</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">mae_h</span><span class="p">,</span> <span class="n">mse_h</span><span class="p">,</span> <span class="n">rmse_h</span><span class="p">,</span> <span class="n">mape_h</span><span class="p">))</span>

        <span class="n">mae_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">per_h</span><span class="p">])</span>
        <span class="n">mse_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">per_h</span><span class="p">])</span>
        <span class="n">rmse_mean</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">per_h</span><span class="p">])</span>
        <span class="n">mape_mean</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">([</span><span class="n">p</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">per_h</span><span class="p">])</span>

        <span class="n">resid_h1</span> <span class="o">=</span> <span class="n">yte</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">yhat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">bds_df</span> <span class="o">=</span> <span class="n">bds_test</span><span class="p">(</span><span class="n">resid_h1</span><span class="p">,</span> <span class="n">n_bootstrap</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">bds_pval</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">bds_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;p_value&quot;</span><span class="p">])</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="n">bds_pval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

        <span class="n">folds_stats</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;fold&quot;</span><span class="p">:</span> <span class="n">fi</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span>
            <span class="s2">&quot;best_cfg&quot;</span><span class="p">:</span> <span class="n">cfg</span><span class="p">,</span>
            <span class="s2">&quot;final_model&quot;</span><span class="p">:</span> <span class="n">final_model</span><span class="p">,</span>
            <span class="s2">&quot;scaler_x&quot;</span><span class="p">:</span> <span class="n">scaler_x</span><span class="p">,</span>
            <span class="s2">&quot;scaler_y&quot;</span><span class="p">:</span> <span class="n">scaler_y</span><span class="p">,</span>
            <span class="s2">&quot;per_h_metrics&quot;</span><span class="p">:</span> <span class="n">per_h</span><span class="p">,</span>
            <span class="s2">&quot;mae_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">mae_mean</span><span class="p">),</span>
            <span class="s2">&quot;mse_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">mse_mean</span><span class="p">),</span>
            <span class="s2">&quot;rmse_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">rmse_mean</span><span class="p">),</span>
            <span class="s2">&quot;mape_mean&quot;</span><span class="p">:</span> <span class="nb">float</span><span class="p">(</span><span class="n">mape_mean</span><span class="p">),</span>
            <span class="s2">&quot;bds_pval_h1&quot;</span><span class="p">:</span> <span class="n">bds_pval</span>
        <span class="p">})</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  fold </span><span class="si">{</span><span class="n">fi</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">: RMSE=</span><span class="si">{</span><span class="n">rmse_mean</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, MAPE=</span><span class="si">{</span><span class="n">mape_mean</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> (saved model in memory)&quot;</span><span class="p">)</span>

    <span class="n">folds_stats_dict</span><span class="p">[</span><span class="s2">&quot;lstm&quot;</span><span class="p">][</span><span class="n">lag</span><span class="p">]</span> <span class="o">=</span> <span class="n">folds_stats</span>
    <span class="n">summary</span> <span class="o">=</span> <span class="n">summarize_folds</span><span class="p">(</span><span class="n">folds_stats</span><span class="p">)</span>
    <span class="n">summary</span><span class="p">[</span><span class="s2">&quot;Lag&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lag</span>
    <span class="n">summary</span><span class="p">[</span><span class="s2">&quot;Best_cfg_mode&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span>
    <span class="n">summary_rows</span><span class="p">[</span><span class="s2">&quot;lstm&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">summary</span><span class="p">)</span>
    <span class="n">df_f</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([{</span><span class="n">k</span><span class="p">:</span><span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;final_model&#39;</span><span class="p">,</span><span class="s1">&#39;scaler_x&#39;</span><span class="p">,</span><span class="s1">&#39;scaler_y&#39;</span><span class="p">)}</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">df_f</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;results/lstm/folds_metrics_lag</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[saved] results/lstm/folds_metrics_lag</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">.csv&quot;</span><span class="p">)</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Save summary CSVs</span>
<span class="c1"># ---------------------------</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">summary_rows</span><span class="p">[</span><span class="s2">&quot;mlp&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;results/mlp/summary_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">summary_rows</span><span class="p">[</span><span class="s2">&quot;lstm&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;results/lstm/summary_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">[Saved summary CSVs] results/mlp/summary_metrics.csv, results/lstm/summary_metrics.csv&quot;</span><span class="p">)</span>

<span class="c1"># ---------------------------</span>
<span class="c1"># Visualization: for each model+lag, plot best fold (by rmse_mean)</span>
<span class="c1"># ---------------------------</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_best_fold_for_model</span><span class="p">(</span><span class="n">model_key</span><span class="p">,</span> <span class="n">lag</span><span class="p">):</span>
    <span class="n">folds_stats</span> <span class="o">=</span> <span class="n">folds_stats_dict</span><span class="p">[</span><span class="n">model_key</span><span class="p">][</span><span class="n">lag</span><span class="p">]</span>
    <span class="c1"># pick best fold (lowest rmse_mean)</span>
    <span class="n">rmse_arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">f</span><span class="p">[</span><span class="s2">&quot;rmse_mean&quot;</span><span class="p">]</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">folds_stats</span><span class="p">])</span>
    <span class="n">best_idx</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">rmse_arr</span><span class="p">))</span>
    <span class="n">entry</span> <span class="o">=</span> <span class="n">folds_stats</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>

    <span class="c1"># recover data splits for this lag</span>
    <span class="n">Xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">Xcvs</span><span class="p">,</span> <span class="n">ycvs</span><span class="p">,</span> <span class="n">Xtests</span><span class="p">,</span> <span class="n">ytests</span> <span class="o">=</span> <span class="n">split_train_val_test_groupKFold</span><span class="p">(</span><span class="n">volatility_full</span><span class="p">,</span> <span class="n">lag</span><span class="p">,</span> <span class="n">n_steps_out</span><span class="p">,</span> <span class="n">n_steps_jump</span><span class="p">)</span>
    <span class="n">Xtr</span><span class="p">,</span> <span class="n">ytr</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">[</span><span class="n">best_idx</span><span class="p">],</span> <span class="n">ys</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>
    <span class="n">Xval</span><span class="p">,</span> <span class="n">yval</span> <span class="o">=</span> <span class="n">Xcvs</span><span class="p">[</span><span class="n">best_idx</span><span class="p">],</span> <span class="n">ycvs</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>
    <span class="n">Xte</span><span class="p">,</span> <span class="n">yte</span> <span class="o">=</span> <span class="n">Xtests</span><span class="p">[</span><span class="n">best_idx</span><span class="p">],</span> <span class="n">ytests</span><span class="p">[</span><span class="n">best_idx</span><span class="p">]</span>

    <span class="c1"># model + scalers</span>
    <span class="n">model_obj</span> <span class="o">=</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;final_model&quot;</span><span class="p">]</span>
    <span class="n">scaler_x</span> <span class="o">=</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;scaler_x&quot;</span><span class="p">]</span>
    <span class="n">scaler_y</span> <span class="o">=</span> <span class="n">entry</span><span class="p">[</span><span class="s2">&quot;scaler_y&quot;</span><span class="p">]</span>

    <span class="c1"># predict</span>
    <span class="k">if</span> <span class="n">model_key</span> <span class="o">==</span> <span class="s2">&quot;lstm&quot;</span><span class="p">:</span>
        <span class="n">Xte_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xte</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">Xte</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xte</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">model_obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte_s</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Xte_s</span> <span class="o">=</span> <span class="n">scaler_x</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">Xte</span><span class="p">)</span>
        <span class="n">yhat</span> <span class="o">=</span> <span class="n">scaler_y</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">model_obj</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xte_s</span><span class="p">))</span>

    <span class="c1"># 1) time series (h1)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ytr</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Train Real&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ytr</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ytr</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">yval</span><span class="p">)),</span> <span class="n">yval</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Val Real&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ytr</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">yval</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ytr</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">yval</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">yte</span><span class="p">)),</span> <span class="n">yte</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test Real&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ytr</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">yval</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ytr</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">yval</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">yte</span><span class="p">)),</span> <span class="n">yhat</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test Pred (h1)&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ytr</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ytr</span><span class="p">)</span><span class="o">+</span><span class="nb">len</span><span class="p">(</span><span class="n">yval</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_key</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2"> best fold </span><span class="si">{</span><span class="n">best_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2"> - Lag </span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2"> (h1)&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;notebooks/figs/</span><span class="si">{</span><span class="n">model_key</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_key</span><span class="si">}</span><span class="s2">_series_lag</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">_bestfold</span><span class="si">{</span><span class="n">best_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># 2) RMSE per fold bars</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rmse_arr</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">rmse_arr</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">rmse_arr</span><span class="p">[</span><span class="n">best_idx</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Fold&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;RMSE mean&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_key</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2"> RMSE per fold - Lag </span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;notebooks/figs/</span><span class="si">{</span><span class="n">model_key</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_key</span><span class="si">}</span><span class="s2">_rmse_per_fold_lag</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="c1"># 3) RMSE per horizon for that best fold</span>
    <span class="n">rmse_h</span> <span class="o">=</span> <span class="n">rmse_per_horiz</span><span class="p">(</span><span class="n">yte</span><span class="p">,</span> <span class="n">yhat</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">rmse_h</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">rmse_h</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Horizon&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;RMSE&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_key</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span><span class="si">}</span><span class="s2"> RMSE per horizon - Lag </span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2"> - best fold </span><span class="si">{</span><span class="n">best_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;notebooks/figs/</span><span class="si">{</span><span class="n">model_key</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_key</span><span class="si">}</span><span class="s2">_rmse_per_horizon_lag</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">_bestfold</span><span class="si">{</span><span class="n">best_idx</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># plot all</span>
<span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">best_cfgs_mlp</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">plot_best_fold_for_model</span><span class="p">(</span><span class="s2">&quot;mlp&quot;</span><span class="p">,</span> <span class="n">lag</span><span class="p">)</span>
<span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="n">best_cfgs_lstm</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">plot_best_fold_for_model</span><span class="p">(</span><span class="s2">&quot;lstm&quot;</span><span class="p">,</span> <span class="n">lag</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Done. All folds re-trained with provided hyperparams, metrics saved, and best-fold plots generated.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt; MLP: retraining &amp; evaluating lag=7
  fold 1: RMSE=0.2162, MAPE=37.27 (saved model in memory)
  fold 2: RMSE=0.2087, MAPE=31.86 (saved model in memory)
  fold 3: RMSE=0.2004, MAPE=31.91 (saved model in memory)
  fold 4: RMSE=0.1936, MAPE=33.23 (saved model in memory)
  fold 5: RMSE=0.2747, MAPE=34.03 (saved model in memory)
[saved] results/mlp/folds_metrics_lag7.csv

&gt;&gt;&gt; MLP: retraining &amp; evaluating lag=14
  fold 1: RMSE=0.4322, MAPE=36.09 (saved model in memory)
  fold 2: RMSE=0.3759, MAPE=35.93 (saved model in memory)
  fold 3: RMSE=0.3235, MAPE=33.57 (saved model in memory)
  fold 4: RMSE=0.3070, MAPE=34.66 (saved model in memory)
  fold 5: RMSE=0.2207, MAPE=37.21 (saved model in memory)
[saved] results/mlp/folds_metrics_lag14.csv

&gt;&gt;&gt; MLP: retraining &amp; evaluating lag=21
  fold 1: RMSE=0.1961, MAPE=40.71 (saved model in memory)
  fold 2: RMSE=0.1971, MAPE=42.98 (saved model in memory)
  fold 3: RMSE=0.2068, MAPE=40.75 (saved model in memory)
  fold 4: RMSE=0.2100, MAPE=39.42 (saved model in memory)
  fold 5: RMSE=0.2376, MAPE=46.39 (saved model in memory)
[saved] results/mlp/folds_metrics_lag21.csv

&gt;&gt;&gt; MLP: retraining &amp; evaluating lag=28
  fold 1: RMSE=0.2179, MAPE=39.13 (saved model in memory)
  fold 2: RMSE=0.2984, MAPE=46.61 (saved model in memory)
  fold 3: RMSE=0.2703, MAPE=41.88 (saved model in memory)
  fold 4: RMSE=0.2671, MAPE=41.24 (saved model in memory)
  fold 5: RMSE=0.3109, MAPE=62.41 (saved model in memory)
[saved] results/mlp/folds_metrics_lag28.csv

&gt;&gt;&gt; LSTM: retraining &amp; evaluating lag=21
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
  fold 1: RMSE=0.2137, MAPE=41.91 (saved model in memory)
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 101ms/step
  fold 2: RMSE=0.2123, MAPE=47.13 (saved model in memory)
WARNING:tensorflow:5 out of the last 5 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x0000019FA1E228E0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
<span class=" -Color -Color-Bold">1/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━</span><span class=" -Color -Color-White">━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 99ms/stepWARNING:tensorflow:6 out of the last 6 calls to &lt;function TensorFlowTrainer.make_predict_function.&lt;locals&gt;.one_step_on_data_distributed at 0x0000019FA1E228E0&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 102ms/step
  fold 3: RMSE=0.2183, MAPE=45.49 (saved model in memory)
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 124ms/step
  fold 4: RMSE=0.2157, MAPE=42.48 (saved model in memory)
<span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 98ms/step
  fold 5: RMSE=0.2238, MAPE=46.40 (saved model in memory)
[saved] results/lstm/folds_metrics_lag21.csv

&gt;&gt;&gt; LSTM: retraining &amp; evaluating lag=28
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 103ms/step
  fold 1: RMSE=0.2203, MAPE=37.24 (saved model in memory)
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 109ms/step
  fold 2: RMSE=0.2650, MAPE=42.55 (saved model in memory)
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 116ms/step
  fold 3: RMSE=0.2941, MAPE=49.02 (saved model in memory)
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
  fold 4: RMSE=0.3070, MAPE=50.20 (saved model in memory)
<span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 108ms/step
  fold 5: RMSE=0.2612, MAPE=47.67 (saved model in memory)
[saved] results/lstm/folds_metrics_lag28.csv

[Saved summary CSVs] results/mlp/summary_metrics.csv, results/lstm/summary_metrics.csv
</pre></div>
</div>
<img alt="_images/f503bc2716f16eb6de4bf1d7d997e984086a9b4cef35eda051fa9b696c51eb12.png" src="_images/f503bc2716f16eb6de4bf1d7d997e984086a9b4cef35eda051fa9b696c51eb12.png" />
<img alt="_images/3a01b33ca8c74795ee3d6c1320ebeb74e3c2c9139a2f89452d152ca750e2c41a.png" src="_images/3a01b33ca8c74795ee3d6c1320ebeb74e3c2c9139a2f89452d152ca750e2c41a.png" />
<img alt="_images/fbaf14a060bb8f8b1814781119fd2a396828c191633d3e1411b9808db0946b1e.png" src="_images/fbaf14a060bb8f8b1814781119fd2a396828c191633d3e1411b9808db0946b1e.png" />
<img alt="_images/aabea61d2c2a15c00d12d13746f21e7994c29e29488ee51351407d366c596df0.png" src="_images/aabea61d2c2a15c00d12d13746f21e7994c29e29488ee51351407d366c596df0.png" />
<img alt="_images/f761bc334b16141a0c7eb6a2c06ddf971b69b1a05804942f7e4a85e0aa16a69d.png" src="_images/f761bc334b16141a0c7eb6a2c06ddf971b69b1a05804942f7e4a85e0aa16a69d.png" />
<img alt="_images/f026f5f28cfb91e43e6a6c567fde7da7a0f5a7d577769330c0a189b1fe5be39b.png" src="_images/f026f5f28cfb91e43e6a6c567fde7da7a0f5a7d577769330c0a189b1fe5be39b.png" />
<img alt="_images/c8cddd5bd6d276f31e7f4bb492cdaaa3c1c7524ecfeba35ba882da1d7de9a8e1.png" src="_images/c8cddd5bd6d276f31e7f4bb492cdaaa3c1c7524ecfeba35ba882da1d7de9a8e1.png" />
<img alt="_images/4d518e3d7f1ba023ad3a497b1a5496096c009ca9c3d1463a3933abeabfd69ace.png" src="_images/4d518e3d7f1ba023ad3a497b1a5496096c009ca9c3d1463a3933abeabfd69ace.png" />
<img alt="_images/acbf794cc9afb0ccf9b79b96f2d98d8a2f5eeccae54343422648622c98946820.png" src="_images/acbf794cc9afb0ccf9b79b96f2d98d8a2f5eeccae54343422648622c98946820.png" />
<img alt="_images/bbd88fff1833d34ea188bca9bb5bbdd81ce37f6cdc3a2c0ce0e7953b5eae49aa.png" src="_images/bbd88fff1833d34ea188bca9bb5bbdd81ce37f6cdc3a2c0ce0e7953b5eae49aa.png" />
<img alt="_images/0e02b3a943cafc58aa80a40bb63a23f48bd0da63c66f211d17e3f2200203a894.png" src="_images/0e02b3a943cafc58aa80a40bb63a23f48bd0da63c66f211d17e3f2200203a894.png" />
<img alt="_images/4f0356e2bb7fe902fe3fe67f763cde4f59cf131c43e2b4922242115b2947b147.png" src="_images/4f0356e2bb7fe902fe3fe67f763cde4f59cf131c43e2b4922242115b2947b147.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">2/2</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 49ms/step
</pre></div>
</div>
<img alt="_images/afc76889856e80d6ec1cdc5651b91f75dd188eb904656a8d4649d4b10046b46b.png" src="_images/afc76889856e80d6ec1cdc5651b91f75dd188eb904656a8d4649d4b10046b46b.png" />
<img alt="_images/23a58fd9412e6a2ac104ce63d29492571bcd58f54d735989f1ebfaf47d7e6e71.png" src="_images/23a58fd9412e6a2ac104ce63d29492571bcd58f54d735989f1ebfaf47d7e6e71.png" />
<img alt="_images/612c762d316d577ab619454b96849439ac5212d43a5341b234ff8c62f8827290.png" src="_images/612c762d316d577ab619454b96849439ac5212d43a5341b234ff8c62f8827290.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Bold">1/1</span> <span class=" -Color -Color-Green">━━━━━━━━━━━━━━━━━━━━</span> <span class=" -Color -Color-Bold">0s</span> 66ms/step
</pre></div>
</div>
<img alt="_images/7b7d728f0c039cce823881e84fe0385b68632f513952c8f25ad121e2e451fd6d.png" src="_images/7b7d728f0c039cce823881e84fe0385b68632f513952c8f25ad121e2e451fd6d.png" />
<img alt="_images/77a5c3129b5018bf8cace4336d6093ae561c99e7d78cd0e3b433b5b3f55a0edb.png" src="_images/77a5c3129b5018bf8cace4336d6093ae561c99e7d78cd0e3b433b5b3f55a0edb.png" />
<img alt="_images/3d78844517e10a57f27ce9d32699191ceee0b285d4cedaa13f721919cef06f4c.png" src="_images/3d78844517e10a57f27ce9d32699191ceee0b285d4cedaa13f721919cef06f4c.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done. All folds re-trained with provided hyperparams, metrics saved, and best-fold plots generated.
</pre></div>
</div>
</div>
</div>
<p>en estos graficos observamos que, mayormente , el error suele aumentar conforme nos movemos a la derecha en la prediccion, lo cual es consistente con lo esperado por la propagacion de errores.
algo interesante ocurre con los dos modelos lstm, en los cuales en lag de tamano 21 se mantiene bastante estable el error hasta la ultima prediccion y en el lag 28 que hace un arco, es posible que en el modelo de 28 dias este capturando algun patron a largo plazo de la serie de tiempo de la volatilidad, pero requeririamos de pruebas mas extensas para comprobar.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sonido</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">winsound</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>  <span class="c1"># Importar el módulo time para las pausas</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="c1"># 1. Reproducir el pitido</span>
    <span class="n">winsound</span><span class="o">.</span><span class="n">Beep</span><span class="p">(</span><span class="mi">1200</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>  <span class="c1"># Frecuencia 1200Hz, duración 300ms</span>

    <span class="c1"># 2. Esperar (silencio)</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>           <span class="c1"># Pausa la ejecución por 0.5 segundos (500ms)</span>
</pre></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="intro.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Welcome to your Jupyter Book</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="simple visible nav section-nav flex-column">
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>